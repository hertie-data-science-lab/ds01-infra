---
phase: 03.1-hardening-deployment-fixes
plan: 03
type: execute
wave: 2
depends_on: ["03.1-01"]
files_modified:
  - scripts/system/deploy.sh
  - config/deploy/profile.d/ds01-gpu-awareness.sh
autonomous: true

must_haves:
  truths:
    - "Udev rules removed (99-ds01-nvidia.rules deleted from /etc/udev/rules.d/)"
    - "Video group restricted to exempt users only (non-exempt users removed)"
    - "Video group exemption logic in ds01-gpu-awareness.sh works (grant file + exempt_users + video group check)"
    - "Docker wrapper isolation in enforcing mode (DS01_ISOLATION_MODE defaults to full)"
    - "nvidia-* wrappers deployed to /usr/local/bin as UX tools"
    - "MOTD deployed and mentions container-only GPU policy"
    - "Device permissions remain at defaults (0666)"
  artifacts:
    - path: "config/deploy/profile.d/ds01-gpu-awareness.sh"
      provides: "GPU awareness layer with video group exemption check"
      contains: "groups.*video"
    - path: "scripts/system/deploy.sh"
      provides: "Video group restriction logic, udev cleanup, nvidia wrapper deployment"
      contains: "video.*restrict"
  key_links:
    - from: "scripts/system/deploy.sh"
      to: "/etc/udev/rules.d/99-ds01-nvidia.rules"
      via: "removes udev rules (design alignment)"
      pattern: "99-ds01-nvidia"
    - from: "config/deploy/profile.d/ds01-gpu-awareness.sh"
      to: "/var/lib/ds01/bare-metal-grants/"
      via: "checks grant file existence for exemption"
      pattern: "grant_file"
    - from: "scripts/system/deploy.sh"
      to: "/usr/local/bin/nvidia-smi"
      via: "deploys nvidia-wrapper.sh as nvidia-smi etc."
      pattern: "nvidia-wrapper"
---

<objective>
Complete bare metal access control deployment: remove udev rules, restrict video group to exempt users only, add video group check to GPU awareness script, deploy nvidia wrappers, and switch Docker wrapper to enforcing mode.

Purpose: Aligns the deployed system with the three-layer GPU access control design from 02.1-DESIGN.md. The audit found several drift points between design and implementation: udev rules still deployed (should be removed), video group has everyone (should be restricted), and exemption logic incomplete. This plan resolves all design-implementation drift.

Output: Updated deploy.sh with video group restriction, udev cleanup, nvidia wrapper deployment. Updated ds01-gpu-awareness.sh with video group exemption check. Docker wrapper in enforcing mode.
</objective>

<execution_context>
@/home/datasciencelab/.claude/get-shit-done/workflows/execute-plan.md
@/home/datasciencelab/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03.1-hardening-deployment-fixes/03.1-CONTEXT.md
@.planning/phases/03.1-hardening-deployment-fixes/03.1-RESEARCH.md
@.planning/phases/02.1-gpu-access-control-research/02.1-DESIGN.md
@.planning/phases/03-access-control/03-03-PLAN.md
@.planning/phases/03.1-hardening-deployment-fixes/03.1-01-SUMMARY.md
@scripts/system/deploy.sh
@config/deploy/profile.d/ds01-gpu-awareness.sh
@scripts/docker/docker-wrapper.sh
@scripts/admin/nvidia-wrapper.sh
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update ds01-gpu-awareness.sh with video group exemption check</name>
  <files>config/deploy/profile.d/ds01-gpu-awareness.sh</files>
  <action>
    **Add video group check** to the exemption logic in ds01-gpu-awareness.sh. The current script checks:
    1. Grant file existence (`/var/lib/ds01/bare-metal-grants/$(whoami).json`)
    2. Config exempt_users list (grep in resource-limits.yaml)

    **Add a third check** for video group membership AFTER the existing two checks and BEFORE the `export CUDA_VISIBLE_DEVICES=""` line:

    ```bash
    # Check if user is in video group (restricted to exempt users by deploy.sh)
    # Video group = bare-metal GPU access privilege (Layer 3 of access control)
    if groups 2>/dev/null | grep -qw video; then
        return 0
    fi
    ```

    The three exemption checks should be in this order:
    1. Grant file (fastest check — single file stat)
    2. Config exempt_users (grep — slightly slower)
    3. Video group membership (groups command — standard)

    If ANY check passes, the user is exempt and the script returns without setting CUDA_VISIBLE_DEVICES.

    **Why video group check matters:** deploy.sh will restrict video group to only exempt users (Plan 03.1-03 Task 2). This makes video group membership a reliable exemption signal, aligned with the 02.1-DESIGN.md three-layer architecture where video group = Layer 3 opt-in.

    **Keep everything else unchanged** — the non-interactive skip, LD_PRELOAD notice, and variable cleanup.
  </action>
  <verify>
    - `bash -n config/deploy/profile.d/ds01-gpu-awareness.sh` exits 0
    - grep for `groups.*video` in the file confirms video group check
    - grep for `grant_file` confirms grant file check still present
    - grep for `exempt` or `grep.*resource-limits` confirms config check still present
    - The three checks appear before `export CUDA_VISIBLE_DEVICES=""`
    - File does NOT contain `exit` (only `return`)
  </verify>
  <done>
    ds01-gpu-awareness.sh has three-tier exemption logic: grant file check, config exempt_users check, and video group membership check. All three must fail before CUDA_VISIBLE_DEVICES is set to empty.
  </done>
</task>

<task type="auto">
  <name>Task 2: Update deploy.sh with udev cleanup, video group restriction, nvidia wrappers, and enforcing mode</name>
  <files>scripts/system/deploy.sh</files>
  <action>
    Modify the "Deploy Access Control" section in deploy.sh. Several changes:

    **1. Remove udev rules (design alignment):**
    Add at the start of the access control section:
    ```bash
    # --- Remove legacy udev rules (design rejected device permission manipulation) ---
    if [ -f /etc/udev/rules.d/99-ds01-nvidia.rules ]; then
        rm -f /etc/udev/rules.d/99-ds01-nvidia.rules
        udevadm control --reload-rules 2>/dev/null || true
        echo -e "  ${GREEN}✓${NC} Removed legacy udev rules (device permissions at defaults)"
    fi
    ```

    **2. Replace the video group sync logic.** The current code (around lines 295-315) adds ALL docker users to video group. Replace with a RESTRICTIVE sync that:
    - Reads exempt users from `bare_metal_access.exempt_users` in resource-limits.yaml
    - Reads users with active grant files in `/var/lib/ds01/bare-metal-grants/`
    - Builds a combined exempt list
    - Adds exempt users to video group (if not already in)
    - **Removes non-exempt users from video group** (critical: this is the restriction)

    ```bash
    # --- Restrict video group to exempt users only ---
    # Video group = Layer 3 bare-metal GPU access privilege
    # Only exempt_users (from config) and users with active grants get video group
    echo -e "${DIM}Restricting video group to exempt users...${NC}"

    # Build exempt list from config
    CONFIG_FILE="$INFRA_ROOT/config/resource-limits.yaml"
    EXEMPT_USERS=$(python3 -c "
    import yaml, sys
    try:
        with open('$CONFIG_FILE') as f:
            config = yaml.safe_load(f)
        bma = config.get('bare_metal_access', {})
        users = bma.get('exempt_users', [])
        print(' '.join(str(u) for u in users))
    except Exception as e:
        print(f'ERROR: {e}', file=sys.stderr)
        sys.exit(1)
    " 2>/dev/null)

    if [ $? -ne 0 ] || [ -z "$EXEMPT_USERS" ]; then
        echo -e "  ${YELLOW}!${NC} WARNING: Failed to read exempt_users from config. Skipping video group sync."
    else
        # Add users with active grant files to exempt list
        if [ -d /var/lib/ds01/bare-metal-grants ]; then
            for grant_file in /var/lib/ds01/bare-metal-grants/*.json; do
                [ -f "$grant_file" ] || continue
                grant_user=$(basename "$grant_file" .json)
                if ! echo "$EXEMPT_USERS" | grep -qw "$grant_user"; then
                    EXEMPT_USERS="$EXEMPT_USERS $grant_user"
                fi
            done
        fi

        # Ensure exempt users are in video group
        for user in $EXEMPT_USERS; do
            if id "$user" &>/dev/null; then
                if ! groups "$user" 2>/dev/null | grep -qw video; then
                    usermod -aG video "$user" 2>/dev/null && \
                        echo -e "  ${GREEN}+${NC} Added $user to video group (exempt)" || true
                fi
            fi
        done

        # Remove non-exempt users from video group
        CURRENT_VIDEO_MEMBERS=$(getent group video 2>/dev/null | cut -d: -f4 | tr ',' ' ')
        for user in $CURRENT_VIDEO_MEMBERS; do
            if ! echo " $EXEMPT_USERS " | grep -qw " $user "; then
                # Not exempt — remove from video group
                gpasswd -d "$user" video 2>/dev/null && \
                    echo -e "  ${YELLOW}-${NC} Removed $user from video group (not exempt)" || true
            fi
        done

        echo -e "  ${GREEN}✓${NC} Video group restricted to exempt users only"
    fi
    ```

    **3. Deploy nvidia-* wrappers (UX tools):**
    Replace the current "Remove legacy nvidia-* wrappers" block (lines 284-293) with deployment:

    ```bash
    # --- Deploy nvidia-* wrappers (UX tools — helpful error messages, NOT security) ---
    NVIDIA_WRAPPER="$INFRA_ROOT/scripts/admin/nvidia-wrapper.sh"
    if [ -f "$NVIDIA_WRAPPER" ]; then
        NVIDIA_COMMANDS="nvidia-smi nvidia-settings nvidia-debugdump nvidia-cuda-mps-control nvidia-cuda-mps-server nvidia-xconfig"
        for cmd in $NVIDIA_COMMANDS; do
            if [ -f "/usr/bin/$cmd" ]; then
                deploy_cmd "$NVIDIA_WRAPPER" "$cmd" "Access Control"
            fi
        done
    fi
    ```

    **4. Docker wrapper isolation mode:**
    The docker wrapper defaults to `full` mode (line 681: `case "${DS01_ISOLATION_MODE:-full}" in`). This is already enforcing mode. No code change needed — just verify the default is `full` (not `monitoring`).

    **Confirm:** The wrapper's default `${DS01_ISOLATION_MODE:-full}` means it runs in enforcing mode unless explicitly overridden. This satisfies SC 13. Add a comment in deploy.sh confirming this:

    ```bash
    # --- Docker wrapper isolation ---
    # Docker wrapper defaults to enforcing mode (DS01_ISOLATION_MODE=full)
    # Set DS01_ISOLATION_MODE=monitoring in environment to switch to monitoring mode
    echo -e "  ${GREEN}✓${NC} Docker wrapper isolation: enforcing (default)"
    ```
  </action>
  <verify>
    - `bash -n scripts/system/deploy.sh` exits 0
    - grep for `99-ds01-nvidia.rules` confirms udev removal logic
    - grep for `gpasswd -d` confirms video group removal of non-exempt users
    - grep for `nvidia-wrapper` confirms wrapper deployment (not removal)
    - grep for `enforcing` or `DS01_ISOLATION_MODE.*full` confirms enforcement note
    - NO grep for `MODE.*0660` or udev rule creation (device permissions at defaults)
    - grep for `Restricting video group` confirms restrictive sync (not additive)
  </verify>
  <done>
    deploy.sh: (1) removes udev rules if present, (2) restricts video group to exempt users + active grant holders (removing non-exempt users), (3) deploys nvidia-* wrappers as UX tools, (4) confirms docker wrapper in enforcing mode. Design-implementation drift fully resolved.
  </done>
</task>

</tasks>

<verification>
1. `bash -n scripts/system/deploy.sh` passes
2. `bash -n config/deploy/profile.d/ds01-gpu-awareness.sh` passes
3. ds01-gpu-awareness.sh has three exemption checks: grant file, config, video group
4. deploy.sh removes udev rules (no 0660 device permissions)
5. deploy.sh restricts video group (removes non-exempt users)
6. deploy.sh deploys nvidia-* wrappers (UX tools)
7. Docker wrapper defaults to enforcing mode (full)
8. Device permissions policy: 0666 defaults, no manipulation
</verification>

<success_criteria>
- Udev rules removed from /etc/udev/rules.d/ (no 99-ds01-nvidia.rules)
- Video group restricted to only exempt_users and active grant holders
- ds01-gpu-awareness.sh checks video group membership as exemption
- nvidia-* wrappers deployed to /usr/local/bin for UX guidance
- Docker wrapper isolation in enforcing mode by default
- Device permissions remain at driver defaults (0666)
- Three-layer architecture fully implemented: CUDA_VISIBLE_DEVICES (L1) + Docker device mapping (L2) + video group exemption (L3)
</success_criteria>

<output>
After completion, create `.planning/phases/03.1-hardening-deployment-fixes/03.1-03-SUMMARY.md`
</output>
