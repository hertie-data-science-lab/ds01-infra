---
phase: 03.1-hardening-deployment-fixes
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - scripts/docker/gpu-availability-checker.py
  - scripts/docker/gpu_allocator_v2.py
autonomous: true

must_haves:
  truths:
    - "GPU availability checker detects full GPUs when MIG is disabled (4x A100 visible)"
    - "GPU allocator loads .members files for correct group resolution"
    - "All GPU allocator/checker errors fail-open with logging (never block container launch)"
    - "Exception handling uses narrow exceptions where failure modes are known, broad+logged as catch-all"
  artifacts:
    - path: "scripts/docker/gpu-availability-checker.py"
      provides: "Full GPU detection alongside MIG instances"
      contains: "_get_physical_gpus"
    - path: "scripts/docker/gpu_allocator_v2.py"
      provides: "Config loading with .members file merge and fail-open error handling"
      contains: "groups_dir"
  key_links:
    - from: "scripts/docker/gpu_allocator_v2.py"
      to: "config/groups/*.members"
      via: "_load_config merges .members files into group config"
      pattern: "member_file"
    - from: "scripts/docker/gpu-availability-checker.py"
      to: "nvidia-smi"
      via: "get_available_gpus queries both MIG and full GPU paths"
      pattern: "_get_physical_gpus"
---

<objective>
Harden the GPU allocator chain (state reader, availability checker, allocator) with fail-open exception handling, and verify that the existing bug fixes (full GPU detection, .members loading) are correct.

Purpose: The GPU allocation pipeline is the critical path for container creation. Two bugs were identified in the cross-phase UAT: (1) availability checker only queried MIG instances, missing full GPUs when MIG is disabled, and (2) allocator didn't load .members files. Both fixes appear to exist as uncommitted changes in the working tree. This plan verifies those fixes and adds systematic fail-open exception handling per OWASP 2025 A10 guidance.

Output: Hardened GPU allocator and availability checker with fail-open error handling, verified .members loading, and verified full GPU detection.
</objective>

<execution_context>
@/home/datasciencelab/.claude/get-shit-done/workflows/execute-plan.md
@/home/datasciencelab/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03.1-hardening-deployment-fixes/03.1-CONTEXT.md
@.planning/phases/03.1-hardening-deployment-fixes/03.1-RESEARCH.md
@scripts/docker/gpu-availability-checker.py
@scripts/docker/gpu_allocator_v2.py
@scripts/docker/get_resource_limits.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Verify and harden GPU availability checker with fail-open exceptions</name>
  <files>scripts/docker/gpu-availability-checker.py</files>
  <action>
    **Verify existing fix:** The working tree has uncommitted changes to `get_available_gpus()`. Confirm it now queries both `_get_all_mig_instances()` AND `_get_physical_gpus()` for full GPUs. The method at line 154 should include both MIG instance detection and full GPU detection (GPUs with no MIG partitions).

    **Add fail-open exception handling** to all public methods. The principle: GPU infrastructure errors must NEVER block container creation. Log the error, return safe defaults.

    Specific changes:

    1. **`get_available_gpus()`** — Wrap the full method body in try/except. On exception, log error via stderr and return empty dict `{}` (fail-open: if we can't determine availability, don't crash the caller).

    2. **`suggest_gpu_for_user()`** — The outer method should catch unexpected exceptions and return a failure dict `{'success': False, 'error': f'Internal error: {e}'}` rather than raising.

    3. **`_get_nvidia_smi_output()`** — Already handles CalledProcessError and FileNotFoundError (returns ""). This is correct. Keep as-is.

    4. **`_get_all_mig_instances()`** — The inner `except Exception: pass` at line 76 silently swallows errors. Change to log to stderr: `print(f"Warning: MIG instance parsing error: {e}", file=sys.stderr)`. This preserves fail-open but adds observability.

    5. **`_get_physical_gpus()`** — Same as above: change `except Exception: pass` to log to stderr.

    6. **`get_allocation_summary()`** — Wrap body in try/except, return a safe default dict on error.

    **Import sys** if not already imported (it is — line 9).

    **Do NOT change the core logic** of GPU detection or the slot ID format. Only add exception handling around existing logic.
  </action>
  <verify>
    - `python3 -c "import ast; ast.parse(open('scripts/docker/gpu-availability-checker.py').read())"` exits 0
    - grep for `_get_physical_gpus` in get_available_gpus method confirms full GPU detection
    - grep for `Warning:.*error` in file confirms fail-open logging (not silent swallow)
    - grep for `except Exception` in file shows all exception handlers have logging
    - No bare `except Exception: pass` remains (all have stderr logging)
  </verify>
  <done>
    GPU availability checker: (1) confirms full GPU detection alongside MIG instances, (2) all exception handlers log to stderr (no silent swallows), (3) public methods fail-open returning safe defaults on unexpected errors.
  </done>
</task>

<task type="auto">
  <name>Task 2: Verify and harden GPU allocator with fail-open exceptions</name>
  <files>scripts/docker/gpu_allocator_v2.py</files>
  <action>
    **Verify existing fix:** The working tree has uncommitted changes to `_load_config()`. Confirm it now loads .members files from `config/groups/{group}.members` and merges them with inline members. The code at lines 105-121 should iterate over groups, read member files, and merge.

    **Add fail-open exception handling** to critical paths:

    1. **`_load_config()`** — The method should catch FileNotFoundError and return `{}` (already does at line 99-100). Additionally, wrap the YAML loading and .members merge in try/except. On YAML parse error, log to stderr and return `{}`. On .members file read error, the inner try/except already catches PermissionError/IOError (line 120-121) — this is correct.

    2. **`_get_user_limits()`** — If config is empty (failed to load), this should return defaults that don't block allocation. Currently returns `defaults.copy()` from config (line 131) which would be `{}` if config empty. Add a safety net: if the returned dict is empty, provide minimal safe defaults:
       ```python
       SAFE_DEFAULTS = {'max_mig_instances': 1, 'allow_full_gpu': False, 'priority': 10}
       ```
       Apply at the end: `return base_limits if base_limits else SAFE_DEFAULTS.copy()`

    3. **`allocate_gpu()`** — The method already has try/finally for lock management. Add a broad exception catch INSIDE the try block (before the finally) that logs the error and returns `(None, f"INTERNAL_ERROR: {e}")` instead of crashing. This ensures the lock is always released AND the caller gets a structured error.

    4. **`allocate_external()`** — Same pattern as allocate_gpu: catch broad Exception inside try, log, return `(None, f"INTERNAL_ERROR: {e}")`.

    5. **`_log_event()`** — Already fails silently (lines 214-228). This is correct. Keep as-is.

    6. **Event logging imports** — The safe fallback at lines 50-55 (no-op log_event) is correct. Keep as-is.

    **Do NOT change the core allocation logic, lock management, or CLI interface.** Only add exception safety around existing logic.
  </action>
  <verify>
    - `python3 -c "import ast; ast.parse(open('scripts/docker/gpu_allocator_v2.py').read())"` exits 0
    - grep for `groups_dir` or `member_file` in _load_config confirms .members loading
    - grep for `SAFE_DEFAULTS` confirms fail-open defaults
    - grep for `INTERNAL_ERROR` confirms fail-open in allocate methods
    - grep for `except.*Exception` shows all critical paths have exception handling
    - `python3 -c "from pathlib import Path; import sys; sys.path.insert(0,'scripts/docker'); exec(open('scripts/docker/gpu_allocator_v2.py').read())"` — no import errors (syntax check only)
  </verify>
  <done>
    GPU allocator: (1) confirms .members file loading in _load_config, (2) _get_user_limits returns safe defaults when config empty, (3) allocate_gpu and allocate_external catch unexpected exceptions and return structured errors (never crash), (4) all error paths log to stderr for observability.
  </done>
</task>

</tasks>

<verification>
1. Both Python files pass syntax check (ast.parse)
2. GPU availability checker detects full GPUs (grep for _get_physical_gpus in get_available_gpus)
3. GPU allocator loads .members files (grep for member_file or groups_dir in _load_config)
4. No silent exception swallowing (all except blocks have logging)
5. Fail-open pattern: infrastructure errors return safe defaults, never raise to caller
6. Lock management unaffected (try/finally preserved)
</verification>

<success_criteria>
- GPU availability checker reports full GPUs when MIG is disabled
- GPU allocator resolves user groups correctly via .members files
- No GPU allocator error can crash container creation (fail-open everywhere)
- All exceptions logged to stderr for post-mortem debugging
- Core allocation logic unchanged (only exception safety added)
</success_criteria>

<output>
After completion, create `.planning/phases/03.1-hardening-deployment-fixes/03.1-02-SUMMARY.md`
</output>
