---
phase: 02-awareness-layer
plan: 03
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - scripts/monitoring/ds01-workloads
autonomous: true

must_haves:
  truths:
    - "Admin can run ds01-workloads and see a table of all GPU workloads (containers + host processes)"
    - "Default table shows: Type, User, GPU(s), Status, Age columns"
    - "Wide mode adds Container/Process ID, Name/Image, CPU%, Memory columns"
    - "By-user mode groups workloads under user headings"
    - "JSON mode outputs raw inventory for scripting"
    - "Filters work: --user, --type, --gpu-only narrow results"
    - "4-tier help system: --help, --info, --concepts, --guided"
  artifacts:
    - path: "scripts/monitoring/ds01-workloads"
      provides: "Unified workload query command"
      min_lines: 150
  key_links:
    - from: "scripts/monitoring/ds01-workloads"
      to: "/var/lib/ds01/workload-inventory.json"
      via: "reads JSON file"
      pattern: "workload-inventory\\.json"
---

<objective>
Create the `ds01-workloads` query command for viewing the unified workload inventory.

Purpose: This is the admin-facing tool that makes detection visible. It reads the inventory file produced by the scanner and presents it in multiple formats: compact table (default), wide table, grouped by user, or raw JSON. It follows the established DS01 CLI patterns (4-tier help, filter flags, familiar output style).

Output: `scripts/monitoring/ds01-workloads` — a Bash script providing the query interface.
</objective>

<execution_context>
@/home/datasciencelab/.claude/get-shit-done/workflows/execute-plan.md
@/home/datasciencelab/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/02-awareness-layer/02-CONTEXT.md
@.planning/phases/02-awareness-layer/02-01-PLAN.md
@.planning/codebase/CONVENTIONS.md
@scripts/monitoring/ds01-events
@scripts/admin/dashboard
@scripts/lib/init.sh
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ds01-workloads with default table output and filter flags</name>
  <files>scripts/monitoring/ds01-workloads</files>
  <action>
Create `scripts/monitoring/ds01-workloads` as a Bash script.

**Script structure:**
- Shebang `#!/bin/bash`, `set -e`
- Comment header with full path and description
- Source `init.sh` for DS01 utilities (colours, logging)
- Constants: `INVENTORY_FILE="/var/lib/ds01/workload-inventory.json"`

**Argument parsing:**
Parse the following flags (use a while loop with case statement, matching the existing ds01-events pattern):
- `--help` / `-h`: Quick usage reference
- `--info`: Full reference with all options explained
- `--concepts`: Educational content explaining workload detection
- `--guided`: Interactive help (suggest common queries)
- `--wide` / `-w`: Show additional columns
- `--by-user`: Group output by user
- `--json`: Output raw inventory JSON (pipe-friendly)
- `--user <name>`: Filter to specific user
- `--type <type>`: Filter by origin type (ds01-managed, devcontainer, compose, raw-docker)
- `--gpu-only`: Show only workloads with GPU access
- `--all`: Include stopped/exited containers (default: running only)

**Pre-flight check:**
- Verify `INVENTORY_FILE` exists. If not, print informative message: "No workload inventory found. The workload detector may not be running yet." with suggestion to check `systemctl status ds01-workload-detector.timer`. Exit 0 (not an error).
- Verify `jq` is available. If not, print "jq is required for ds01-workloads. Install with: sudo apt-get install jq". Exit 1.

**Default table output (compact):**

Columns: `TYPE`, `USER`, `GPU(S)`, `STATUS`, `AGE`, `NAME`

Build using jq to extract and format data from inventory JSON. The output should feel like `docker ps`:

```
TYPE           USER      GPU(S)    STATUS    AGE    NAME
ds01-managed   alice     0:1       running   2h     alice-pytorch
devcontainer   bob       0:2       running   45m    vsc-ml-project
raw-docker     unknown   -         running   3d     test-container
host-process   charlie   2048MB    active    10m    python train.py
```

Implementation approach:
- Use jq to merge containers and host_processes into a unified list
- For containers: TYPE=origin, GPU(S)=gpu_devices joined or "-" if none, STATUS=status, AGE=computed from detected_at, NAME=container name
- For host processes: TYPE="host-process", GPU(S)=gpu_memory_mb + "MB", STATUS="active", AGE=computed from detected_at, NAME=cmdline (truncated to 40 chars)
- Age calculation: compute difference between now and detected_at, format as "Xd", "Xh", "Xm", or "Xs"
- Colour code TYPE column: green for ds01-managed, yellow for devcontainer/compose, red for raw-docker/host-process

**Filtering (applied before output):**
- `--user`: jq select where user matches
- `--type`: jq select where origin/type matches
- `--gpu-only`: jq select where has_gpu==true (containers) or always true (host processes are GPU by definition)
- `--all`: include all statuses; default: filter to running/active only

**Summary line at bottom:**
Print a summary: "X containers (Y with GPU), Z host GPU processes — last scan: <timestamp>"

Make the script executable (`chmod +x`).
  </action>
  <verify>
Run `bash -n scripts/monitoring/ds01-workloads` to verify no syntax errors.

Verify the script is executable:
```bash
ls -la scripts/monitoring/ds01-workloads
```

Verify help output works:
```bash
scripts/monitoring/ds01-workloads --help
```
(Should show usage even without inventory file — help should work regardless.)

Verify it handles missing inventory gracefully:
```bash
scripts/monitoring/ds01-workloads 2>&1
```
(Should show "No workload inventory found" message if no inventory exists.)
  </verify>
  <done>
`ds01-workloads` displays compact table with TYPE, USER, GPU(S), STATUS, AGE, NAME columns. Supports --user, --type, --gpu-only, --all filters. Handles missing inventory gracefully.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add --wide, --by-user, --json modes and 4-tier help</name>
  <files>scripts/monitoring/ds01-workloads</files>
  <action>
Extend `ds01-workloads` with additional output modes and the full help system.

**Wide mode (`--wide`):**

Additional columns beyond the default: `ID`, `IMAGE`, `CPU%`, `MEM`

```
TYPE           USER      GPU(S)    STATUS    AGE    ID            NAME                  IMAGE                    CPU%    MEM
ds01-managed   alice     0:1       running   2h     abc123def456  alice-pytorch          ds01/pytorch:latest      45%     8.2GB
host-process   charlie   2048MB    active    10m    PID:12345     python train.py        -                        -       -
```

- ID: container ID (12 chars) for containers, "PID:XXXX" for host processes
- IMAGE: container image for containers, "-" for host processes
- CPU%/MEM: live values from `docker stats --no-stream --format` for RUNNING containers only. For stopped containers and host processes, show "-". Use a single `docker stats` call for all running containers at once (not per-container) for efficiency. Cache the stats output and look up by container ID.

**By-user mode (`--by-user`):**

Group workloads under user headings:

```
alice (2 workloads, 2 GPUs)
  TYPE           GPU(S)    STATUS    AGE    NAME
  ds01-managed   0:1       running   2h     alice-pytorch
  ds01-managed   0:2       running   1h     alice-jupyter

bob (1 workload, 1 GPU)
  TYPE           GPU(S)    STATUS    AGE    NAME
  devcontainer   0:3       running   45m    vsc-ml-project

unknown (1 workload, 0 GPUs)
  TYPE           GPU(S)    STATUS    AGE    NAME
  raw-docker     -         running   3d     test-container
```

- Sort users alphabetically, "unknown" always last
- Show user summary line with workload count and GPU count
- Can be combined with `--wide` for additional columns
- Can be combined with filters (`--gpu-only`, `--type`)

**JSON mode (`--json`):**

Output the raw inventory JSON (or filtered subset) to stdout. No formatting, no colours.
- If filters are applied (`--user`, `--type`, `--gpu-only`), apply jq filtering before output
- Output is valid JSON suitable for piping to `jq`
- When `--json` is used, skip the summary line

**4-tier help system:**

`--help` (quick reference):
```
Usage: ds01-workloads [OPTIONS]

Show all detected GPU workloads (containers and host processes).

Options:
  -w, --wide       Show additional columns (ID, Image, CPU%, Memory)
  --by-user        Group workloads by user
  --json           Output raw JSON (for scripting)
  --user NAME      Filter by user
  --type TYPE      Filter by type (ds01-managed, devcontainer, compose, raw-docker)
  --gpu-only       Show only GPU workloads
  --all            Include stopped/exited (default: running only)

Info: ds01-workloads --info | Concepts: ds01-workloads --concepts
```

`--info` (full reference):
- All options with detailed explanations
- Output format descriptions
- Example commands for common queries
- Information about the inventory file location and scan frequency

`--concepts` (educational):
- What workload detection does and why
- Container classification: how DS01 determines origin
- Host process detection: how nvidia-smi + /proc attribution works
- Transient process filtering: why brief GPU usage may not appear
- Managed vs unmanaged: what it means for enforcement

`--guided` (interactive):
- Present numbered options:
  1. Show all GPU workloads
  2. Show workloads for a specific user
  3. Show unmanaged containers only
  4. Show host GPU processes only
  5. Export as JSON
- Read user selection, construct and run the appropriate command
  </action>
  <verify>
Run `bash -n scripts/monitoring/ds01-workloads` to verify no syntax errors.

Test each help tier:
```bash
scripts/monitoring/ds01-workloads --help
scripts/monitoring/ds01-workloads --info
scripts/monitoring/ds01-workloads --concepts
```
Each should produce output without errors (--guided requires interactive input, skip in automated verify).

Verify --json flag is handled:
```bash
grep -c "json" scripts/monitoring/ds01-workloads
```
Should return multiple matches.
  </verify>
  <done>
`ds01-workloads` is complete with all output modes: default compact table, --wide (with live docker stats), --by-user (grouped), --json (pipe-friendly). Full 4-tier help system implemented. All modes combinable with filter flags.
  </done>
</task>

</tasks>

<verification>
1. `bash -n scripts/monitoring/ds01-workloads` passes (no syntax errors)
2. `scripts/monitoring/ds01-workloads --help` shows quick reference
3. `scripts/monitoring/ds01-workloads --info` shows full reference
4. `scripts/monitoring/ds01-workloads --concepts` shows educational content
5. Script handles missing inventory file gracefully (informative message, not crash)
6. Script handles missing jq gracefully (clear install instructions)
7. `--json` outputs valid JSON (when inventory exists)
</verification>

<success_criteria>
- Admin can query unified workload inventory from a single command
- Default output is a compact table feeling like `docker ps`
- Wide mode adds live resource usage
- By-user mode provides per-user grouping
- JSON mode enables scripting and piping to jq
- All filter flags work (--user, --type, --gpu-only, --all)
- 4-tier help system complete (--help, --info, --concepts, --guided)
</success_criteria>

<output>
After completion, create `.planning/phases/02-awareness-layer/02-03-SUMMARY.md`
</output>
