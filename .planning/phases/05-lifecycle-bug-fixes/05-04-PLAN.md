---
phase: 05-lifecycle-bug-fixes
plan: 04
type: execute
wave: 2
depends_on: ["05-01", "05-02", "05-03"]
files_modified:
  - scripts/maintenance/cleanup-stale-gpu-allocations.sh
  - config/deploy/cron.d/ds01-maintenance
autonomous: true

must_haves:
  truths:
    - "Post-removal GPU health check detects orphaned processes via nvidia-smi"
    - "Orphaned GPU processes are killed after container removal"
    - "GPU reset (nvidia-smi -r) only runs if no other containers share that GPU"
    - "MIG-shared GPUs alert admin instead of resetting (prevents breaking other containers)"
    - "Cron schedule has check-idle-containers.sh and cleanup-stale-containers.sh running at different minutes (no collision)"
    - "Idle check cron conflicts resolved (currently both idle and stale container cleanup at :30)"
  artifacts:
    - path: "scripts/maintenance/cleanup-stale-gpu-allocations.sh"
      provides: "GPU allocation cleanup with post-removal health verification"
      contains: "query-compute-apps"
    - path: "config/deploy/cron.d/ds01-maintenance"
      provides: "Updated cron schedule with no timing collisions"
  key_links:
    - from: "cleanup-stale-gpu-allocations.sh"
      to: "nvidia-smi --query-compute-apps"
      via: "CLI query for orphaned GPU processes"
      pattern: "query-compute-apps"
    - from: "cleanup-stale-gpu-allocations.sh"
      to: "nvidia-smi -r"
      via: "GPU reset command (only if safe)"
      pattern: "nvidia-smi.*-r"
---

<objective>
Add post-removal GPU health verification (orphaned process detection + kill + safe reset) to GPU cleanup script, and fix the cron schedule collision where both idle-check and stale-container-cleanup run at :30.

Purpose: LIFE-05 requires GPU allocations released reliably when containers stop. The SLURM epilog pattern (check for orphaned processes, kill, reset GPU) prevents GPU leaks that survive container removal. The cron collision means idle checks and stale container cleanup could interfere.

Output: Updated cleanup-stale-gpu-allocations.sh with GPU health verification, updated cron schedule.
</objective>

<execution_context>
@/home/datasciencelab/.claude/get-shit-done/workflows/execute-plan.md
@/home/datasciencelab/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-lifecycle-bug-fixes/05-CONTEXT.md
@.planning/phases/05-lifecycle-bug-fixes/05-RESEARCH.md
@scripts/maintenance/cleanup-stale-gpu-allocations.sh
@config/deploy/cron.d/ds01-maintenance
@.planning/phases/05-lifecycle-bug-fixes/05-01-SUMMARY.md
@.planning/phases/05-lifecycle-bug-fixes/05-03-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add post-removal GPU health verification to cleanup script</name>
  <files>scripts/maintenance/cleanup-stale-gpu-allocations.sh</files>
  <action>
  Add a `verify_gpu_health()` function implementing the SLURM epilog pattern:

  **1. Function `verify_gpu_health(gpu_uuid)`:**
  - After the existing `release-stale` command completes, for each GPU that had allocations released, run health verification
  - Query orphaned processes: `nvidia-smi --query-compute-apps=pid,process_name,used_memory --format=csv,noheader --id="$gpu_uuid"`
  - If orphaned processes found:
    a. Log WARNING with process details
    b. Extract PIDs and kill them: `kill -9 "$pid"` for each
    c. Check if GPU is shared (MIG): `docker ps --filter "label=ds01.gpu.uuid=$gpu_uuid" --format "{{.Names}}"`
    d. If NO other containers use the GPU: run `nvidia-smi -r -i "$gpu_uuid"` to reset
    e. If GPU IS shared (MIG/other containers): log ERROR and DO NOT reset — "Manual intervention required"
    f. Log event via `log_event "gpu.health_check" ...` with orphan details

  **2. Integrate health check into main flow:**
  - After the existing `python3 "$GPU_ALLOCATOR" release-stale` call succeeds
  - Parse the output to extract GPU UUIDs that were released (grep for GPU-xxx or MIG-xxx patterns)
  - For each released GPU UUID, call `verify_gpu_health "$gpu_uuid"`
  - If no specific UUIDs extractable from output, run a general health check on ALL GPUs that have no running containers

  **3. Add a standalone health check mode:**
  - Add `--health-check` flag support: when called with this flag, skip release-stale and just verify all GPUs
  - This allows running health checks independently (e.g., after manual container removal)
  - Check all GPUs: `nvidia-smi --query-gpu=uuid --format=csv,noheader` → for each, verify_gpu_health

  **4. Source shared libraries:**
  - Source `$INFRA_ROOT/scripts/lib/init.sh` for standard utilities (currently missing, the script doesn't source it)
  - Source ds01_events.sh for log_event (already done)

  **Implementation notes:**
  - `nvidia-smi --query-compute-apps` may return nothing for MIG instances if the MIG UUID format differs — handle gracefully
  - `nvidia-smi -r` (GPU reset) requires root and may fail if GPU is in use — handle error and log
  - The GPU UUID format from docker labels may be `GPU-xxx` or `MIG-xxx` — handle both
  - Keep the existing release-stale flow intact, add health check as a post-step
  </action>
  <verify>bash -n scripts/maintenance/cleanup-stale-gpu-allocations.sh && grep -c "query-compute-apps" scripts/maintenance/cleanup-stale-gpu-allocations.sh</verify>
  <done>cleanup-stale-gpu-allocations.sh has post-removal GPU health verification that detects orphaned processes, kills them, and safely resets GPU only when not shared</done>
</task>

<task type="auto">
  <name>Task 2: Fix cron schedule collision and update timing</name>
  <files>config/deploy/cron.d/ds01-maintenance</files>
  <action>
  Fix the cron timing collision: currently both `check-idle-containers.sh` and `cleanup-stale-containers.sh` run at :30 past the hour.

  Updated schedule (spread across the hour, maintaining the logical order):
  - **:05** — GPU health check + cleanup stale allocations (was :15)
  - **:20** — Check idle containers (was :30) — moved earlier to avoid collision
  - **:35** — Enforce max runtime (was :45) — shifted to maintain spacing
  - **:50** — Cleanup stale containers (was :30 — collision!) — moved to :50

  Update the Container Lifecycle Management section:
  ```
  # Check for idle containers (:20 past each hour)
  20 * * * * root $INFRA_ROOT/scripts/monitoring/check-idle-containers.sh >> /var/log/ds01/idle-cleanup.log 2>&1

  # Enforce max runtime (:35 past each hour)
  35 * * * * root $INFRA_ROOT/scripts/maintenance/enforce-max-runtime.sh >> /var/log/ds01/runtime-enforcement.log 2>&1

  # Clean up stale GPU allocations + health check (:05 past each hour)
  5 * * * * root $INFRA_ROOT/scripts/maintenance/cleanup-stale-gpu-allocations.sh >> /var/log/ds01/gpu-cleanup.log 2>&1

  # Clean up stopped containers (:50 past each hour)
  50 * * * * root $INFRA_ROOT/scripts/maintenance/cleanup-stale-containers.sh >> /var/log/ds01/container-cleanup.log 2>&1
  ```

  Also update the `check-idle-containers.sh` log path reference (line 33 currently says `check-idle-containers.sh` but points to `maintenance/` — verify the path is correct: it should be `$INFRA_ROOT/scripts/monitoring/check-idle-containers.sh`).

  Also update the section comment to document the logical flow:
  ```
  # Container Lifecycle Management
  # Flow: GPU cleanup (:05) -> idle check (:20) -> runtime enforce (:35) -> container cleanup (:50)
  ```
  </action>
  <verify>grep -c ":30\|:45\|:15" config/deploy/cron.d/ds01-maintenance | grep -v "check-waste" && echo "Old times should be gone"</verify>
  <done>Cron schedule has no timing collisions, logical ordering maintained: GPU cleanup -> idle check -> runtime enforce -> container cleanup</done>
</task>

</tasks>

<verification>
1. `bash -n scripts/maintenance/cleanup-stale-gpu-allocations.sh` — syntax check passes
2. `grep "query-compute-apps" scripts/maintenance/cleanup-stale-gpu-allocations.sh` — orphaned process detection present
3. `grep "nvidia-smi.*-r" scripts/maintenance/cleanup-stale-gpu-allocations.sh` — GPU reset present
4. `grep "docker ps.*filter.*gpu" scripts/maintenance/cleanup-stale-gpu-allocations.sh` — shared GPU check present
5. Cron schedule: no two container lifecycle jobs at the same minute
6. `grep "scripts/monitoring/check-idle-containers.sh" config/deploy/cron.d/ds01-maintenance` — correct path
7. All 4 lifecycle cron entries present with unique minute values
</verification>

<success_criteria>
- GPU health verification detects and kills orphaned processes
- GPU reset only runs when GPU is not shared (MIG safety)
- Cron schedule has no collisions between lifecycle jobs
- All scripts pass bash -n syntax check
- Logical flow ordering maintained in cron: cleanup GPU -> idle check -> runtime -> cleanup containers
</success_criteria>

<output>
After completion, create `.planning/phases/05-lifecycle-bug-fixes/05-04-SUMMARY.md`
</output>
