---
phase: 05-lifecycle-bug-fixes
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - scripts/monitoring/check-idle-containers.sh
  - config/runtime/resource-limits.yaml
autonomous: true

must_haves:
  truths:
    - "GPU utilisation (<5%) is the primary idle signal, checked via nvidia-smi per container's GPU UUID"
    - "Containers in their first 30 minutes are never idle-checked (grace period uses Docker StartedAt)"
    - "Dev containers are exempt from idle timeout (only subject to max_runtime)"
    - "Idle warnings and stop notifications use wall messages, not files in $HOME or /workspace"
    - "Keep-alive file older than 24 hours is ignored"
    - "SIGTERM grace period is 60 seconds (not 10)"
    - "Containers with unknown owner get ds01.user=unknown label and strictest idle timeout"
  artifacts:
    - path: "scripts/monitoring/check-idle-containers.sh"
      provides: "GPU-aware multi-signal idle detection with grace period and wall notifications"
      contains: "nvidia-smi.*query-gpu.*utilization"
    - path: "config/runtime/resource-limits.yaml"
      provides: "Dev container idle_timeout set to null, created_container_timeout added"
      contains: "idle_timeout: null"
  key_links:
    - from: "check-idle-containers.sh"
      to: "nvidia-smi"
      via: "CLI query for GPU utilisation per GPU UUID"
      pattern: "nvidia-smi.*--id="
    - from: "check-idle-containers.sh"
      to: "wall"
      via: "wall command for terminal broadcast"
      pattern: "wall"
---

<objective>
Add GPU utilisation as primary idle signal, implement 30-minute grace period, exempt dev containers from idle timeout, switch notifications to wall messages, enforce 24-hour keep-alive limit, and increase SIGTERM grace to 60 seconds.

Purpose: LIFE-01 requires idle timeout enforced for all container types with GPU utilisation as primary signal. Current check-idle-containers.sh only checks CPU — GPU workloads with 0% CPU but 100% GPU are incorrectly flagged as idle.

Output: Updated check-idle-containers.sh with multi-signal idle detection, updated resource-limits.yaml with devcontainer exemption config.
</objective>

<execution_context>
@/home/datasciencelab/.claude/get-shit-done/workflows/execute-plan.md
@/home/datasciencelab/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-lifecycle-bug-fixes/05-CONTEXT.md
@.planning/phases/05-lifecycle-bug-fixes/05-RESEARCH.md
@scripts/monitoring/check-idle-containers.sh
@config/runtime/resource-limits.yaml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update resource-limits.yaml for Phase 5 config changes</name>
  <files>config/runtime/resource-limits.yaml</files>
  <action>
  Update the container_types section:
  1. Change `devcontainer.idle_timeout` from `30m` to `null` (exempt from idle timeout per CONTEXT decision)
  2. Add `created_container_timeout: 30m` under `policies` section (for created-never-started cleanup)
  3. Add `gpu_idle_threshold: 5` under `policies` section (GPU utilisation % threshold for idle detection)
  4. Add `grace_period: 30m` under `policies` section (startup grace period before idle detection begins)
  5. Add `keepalive_max_duration: 24h` under `policies` section (max time .keep-alive file is respected)
  6. Add `sigterm_grace_seconds: 60` under `policies` section (SIGTERM grace period for GPU containers)
  7. Add `gpu_hold_after_manual_stop: 15m` under `policies` section (GPU hold duration when user manually stops)

  Do NOT change any existing values other than devcontainer.idle_timeout. Add new fields to the existing `policies` section.
  </action>
  <verify>python3 -c "import yaml; c=yaml.safe_load(open('config/runtime/resource-limits.yaml')); assert c['container_types']['devcontainer']['idle_timeout'] is None; assert c['policies']['gpu_idle_threshold'] == 5; assert c['policies']['grace_period'] == '30m'; assert c['policies']['sigterm_grace_seconds'] == 60; print('OK')"</verify>
  <done>resource-limits.yaml has devcontainer idle_timeout null, gpu_idle_threshold 5, grace_period 30m, keepalive_max_duration 24h, sigterm_grace_seconds 60, gpu_hold_after_manual_stop 15m, created_container_timeout 30m</done>
</task>

<task type="auto">
  <name>Task 2: Rewrite idle detection in check-idle-containers.sh</name>
  <files>scripts/monitoring/check-idle-containers.sh</files>
  <action>
  This is a significant rewrite of the idle detection logic. Key changes:

  **1. Add GPU utilisation check function `check_gpu_idle()`:**
  - Takes container name and gets its GPU UUID from Docker label `ds01.gpu.uuid` or by inspecting DeviceRequests
  - Calls `nvidia-smi --query-gpu=utilization.gpu --format=csv,noheader,nounits --id="$gpu_uuid"` to get GPU util %
  - Returns "idle" if GPU util < threshold (read from policies.gpu_idle_threshold, default 5%)
  - Falls through to secondary signals (CPU, network) if GPU is idle
  - Multi-signal logic: GPU idle AND CPU idle (< 1%) = idle. GPU idle but CPU active = NOT idle (data loading). GPU active = NOT idle.
  - If nvidia-smi fails (e.g., MIG instance, driver issue), fall back to CPU-only detection (fail-open)

  **2. Add 30-minute startup grace period:**
  - In `process_container_universal()`, BEFORE checking idle status, check container's `StartedAt` timestamp from Docker API
  - If container age < grace_period (30m from policies), skip idle detection entirely and log "grace_period"
  - Use `docker inspect --format='{{.State.StartedAt}}'` — do NOT use state file age

  **3. Exempt dev containers from idle timeout:**
  - In `process_container_universal()`, after getting container_type, if type is "devcontainer", skip idle detection entirely
  - Log: "Skipping devcontainer $container (exempt from idle timeout)"

  **4. Replace file-based notifications with wall messages:**
  - Rewrite `send_warning()` to use `wall` instead of writing to `$user_home/.ds01-idle-warning` and `/workspace/.idle-warning.txt`
  - Remove ALL file creation (no warning_file, no notification_file)
  - Message format: plain text (no emoji in wall messages — terminal encoding issues), include container name, time remaining, and how to prevent
  - Use `echo "$message" | wall` for broadcast to all terminals (root cron has permission)
  - Rewrite `stop_idle_container()` notification to also use wall instead of file

  **5. Enforce 24-hour keep-alive limit:**
  - In `stop_idle_container()`, when checking .keep-alive file, also check its mtime
  - If .keep-alive mtime > 24 hours old, ignore it and proceed with idle stop
  - Use `find /workspace/.keep-alive -mmin +1440` or `stat --format=%Y` to check age
  - Log when keep-alive is expired: "Container $container .keep-alive expired (>24h), proceeding with idle stop"

  **6. Change SIGTERM grace period from 10s to 60s:**
  - In `stop_idle_container()`, change `docker stop -t 10` to `docker stop -t 60`

  **7. Label unattributable containers:**
  - In the main loop, if `get_container_owner()` returns empty, apply `ds01.user=unknown` label: `docker label "$container" "ds01.user=unknown"` (note: Docker doesn't support `docker label` — instead, just set `username="unknown"` and log it. The label is already read elsewhere.)
  - The username="unknown" path already exists, just ensure it reaches the strictest timeout via container_types.unknown config

  **8. Remove legacy `process_container()` function:**
  - Delete the entire `process_container()` function (lines ~588-657) — it's marked as legacy backwards compatibility and is never called by `monitor_containers()` which uses `process_container_universal()`.

  **Important implementation notes:**
  - Keep `is_container_active()` as a helper but refactor it to be `is_container_active_secondary()` — it provides the CPU/network/process checks that are now secondary signals
  - The primary check is `check_gpu_idle()`, secondary is existing CPU/network checks
  - Container GPU UUID: try `ds01.gpu.uuid` label first, then fall back to parsing DeviceRequests from docker inspect
  - For MIG instances, nvidia-smi `--id=` accepts both GPU UUID and MIG UUID — use whichever we can find
  - If container has multiple GPUs, check ALL of them — container is idle only if ALL GPUs are idle
  </action>
  <verify>bash -n scripts/monitoring/check-idle-containers.sh && echo "Syntax OK"</verify>
  <done>check-idle-containers.sh has GPU utilisation as primary idle signal via nvidia-smi, 30-minute grace period using Docker StartedAt, devcontainer exemption, wall-based notifications (no file creation), 24-hour keep-alive limit, 60-second SIGTERM grace, and legacy process_container() removed</done>
</task>

</tasks>

<verification>
1. `bash -n scripts/monitoring/check-idle-containers.sh` — syntax check passes
2. `grep -c "nvidia-smi" scripts/monitoring/check-idle-containers.sh` — at least 1 occurrence (GPU util check)
3. `grep -c "wall" scripts/monitoring/check-idle-containers.sh` — at least 1 occurrence (wall notification)
4. `grep -c "grace_period\|1800\|30.*min" scripts/monitoring/check-idle-containers.sh` — grace period present
5. `grep "docker stop -t 60" scripts/monitoring/check-idle-containers.sh` — 60s SIGTERM
6. `grep "devcontainer.*exempt\|devcontainer.*skip" scripts/monitoring/check-idle-containers.sh` — devcontainer exemption
7. No occurrences of `.ds01-idle-warning` or `.idle-warning.txt` (file-based notifications removed)
8. YAML validation: `python3 -c "import yaml; yaml.safe_load(open('config/runtime/resource-limits.yaml'))"`
</verification>

<success_criteria>
- GPU utilisation check via nvidia-smi is the primary idle signal
- 30-minute grace period prevents false positives during startup
- Dev containers are exempt from idle timeout
- All notifications use wall (no file creation in $HOME or /workspace)
- Keep-alive file ignored after 24 hours
- SIGTERM grace is 60 seconds
- Script passes bash -n syntax check
</success_criteria>

<output>
After completion, create `.planning/phases/05-lifecycle-bug-fixes/05-01-SUMMARY.md`
</output>
