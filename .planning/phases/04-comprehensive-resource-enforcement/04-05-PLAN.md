---
phase: 04-comprehensive-resource-enforcement
plan: 05
type: execute
wave: 3
depends_on: ["04-01", "04-02", "04-03"]
files_modified:
  - scripts/monitoring/collect-resource-stats.sh
  - scripts/docker/event-logger.py
  - testing/integration/test_resource_enforcement.sh
  - config/deploy/cron.d/ds01-resource-monitor
autonomous: true

must_haves:
  truths:
    - "PSI metrics collected per user slice every 60 seconds via cron"
    - "OOM events logged to ds01 event log with user attribution"
    - "Integration test validates memory enforcement end-to-end"
    - "Resource stats viewable via existing ds01-events query tool"
  artifacts:
    - path: "scripts/monitoring/collect-resource-stats.sh"
      provides: "PSI and resource stats collection per user slice"
      min_lines: 50
    - path: "testing/integration/test_resource_enforcement.sh"
      provides: "Integration test for resource enforcement"
      min_lines: 40
    - path: "config/deploy/cron.d/ds01-resource-monitor"
      provides: "Cron job for periodic resource stats collection"
      contains: "collect-resource-stats"
  key_links:
    - from: "scripts/monitoring/collect-resource-stats.sh"
      to: "/sys/fs/cgroup/ds01.slice/"
      via: "reads PSI and resource metrics per user slice"
      pattern: "memory.pressure\\|cpu.pressure"
    - from: "scripts/monitoring/collect-resource-stats.sh"
      to: "scripts/docker/event-logger.py"
      via: "logs resource events"
      pattern: "log_event\\|event-logger"
---

<objective>
Add PSI monitoring, OOM event logging, and integration tests for the resource enforcement system.

Purpose: Monitoring closes the loop — without it, enforcement is invisible. PSI metrics detect resource pressure before hard limits trigger. OOM logging provides an audit trail. Integration tests validate the entire enforcement chain works.

Output: Resource stats collection script with cron, OOM event integration, integration test script.
</objective>

<execution_context>
@/home/datasciencelab/.claude/get-shit-done/workflows/execute-plan.md
@/home/datasciencelab/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/04-comprehensive-resource-enforcement/04-CONTEXT.md
@.planning/phases/04-comprehensive-resource-enforcement/04-01-SUMMARY.md
@.planning/phases/04-comprehensive-resource-enforcement/04-02-SUMMARY.md
@scripts/monitoring/check-idle-containers.sh
@scripts/docker/event-logger.py
@config/deploy/cron.d/
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create PSI/resource monitoring script and OOM event logging</name>
  <files>
    scripts/monitoring/collect-resource-stats.sh
    config/deploy/cron.d/ds01-resource-monitor
    scripts/system/deploy.sh
  </files>
  <action>
1. **Create scripts/monitoring/collect-resource-stats.sh** — A monitoring script that collects resource usage and PSI metrics per user slice. Follow patterns from existing monitoring scripts (check-idle-containers.sh):

   - Run as root (cron context)
   - Source init.sh for logging functions
   - Iterate over all ds01-*-*.slice directories under `/sys/fs/cgroup/ds01.slice/`
   - For each user slice, collect:
     - `memory.current` (bytes) and `memory.max` (bytes) — calculate usage percentage
     - `pids.current` and `pids.max`
     - `memory.pressure` (parse `some avg10=X.XX` and `full avg10=X.XX`)
     - `cpu.pressure` (parse `some avg10=X.XX` and `full avg10=X.XX`)
     - `memory.events` (parse `oom` and `oom_kill` counters for OOM detection)
   - Extract username and group from slice name: `ds01-{group}-{user}.slice` → group, user
   - Log summary to `/var/log/ds01/resource-stats.log` (one JSON line per user per collection)
   - Format: `{"timestamp":"ISO","user":"...","group":"...","memory_current_bytes":N,"memory_max_bytes":N,"memory_pct":N,"pids_current":N,"pids_max":N,"psi_memory_some_avg10":N,"psi_memory_full_avg10":N,"psi_cpu_some_avg10":N,"psi_cpu_full_avg10":N,"oom_count":N,"oom_kill_count":N}`
   - If PSI files don't exist (older kernel), skip those fields
   - **OOM detection**: Track `memory.events` oom_kill counter. Keep a state file `/var/lib/ds01/resource-stats/oom-counts.json` with last-seen oom_kill count per user. When count increases, log an OOM event via event-logger: `log_event "resource.oom_kill" "$user" "resource-monitor" count="$new_kills"`
   - Log to event system (best-effort, never blocks): use the `ds01_events.sh` library if available
   - CLI: `collect-resource-stats.sh [--verbose]`
   - Handle gracefully: slices without controller files, empty directories

2. **Create config/deploy/cron.d/ds01-resource-monitor** — Cron job that runs collect-resource-stats.sh every minute:
   ```
   * * * * * root /opt/ds01-infra/scripts/monitoring/collect-resource-stats.sh >> /var/log/ds01/resource-monitor.log 2>&1
   ```
   Follow the pattern of existing cron jobs in config/deploy/cron.d/.

3. **Update deploy.sh** — Ensure collect-resource-stats.sh is deployed as a symlink (ds01-resource-stats) and the cron job is deployed. The deploy.sh already has a cron deployment section — verify the new cron file will be picked up.
  </action>
  <verify>
    - `bash -n scripts/monitoring/collect-resource-stats.sh` (syntax check)
    - `grep -q "memory.pressure\|cpu.pressure" scripts/monitoring/collect-resource-stats.sh` (reads PSI)
    - `grep -q "memory.events\|oom_kill" scripts/monitoring/collect-resource-stats.sh` (OOM detection)
    - `cat config/deploy/cron.d/ds01-resource-monitor` (cron config valid)
  </verify>
  <done>PSI metrics and OOM events collected per user slice every minute, logged to event system</done>
</task>

<task type="auto">
  <name>Task 2: Create integration test for resource enforcement</name>
  <files>
    testing/integration/test_resource_enforcement.sh
  </files>
  <action>
Create an integration test script that validates the resource enforcement chain end-to-end. This test is designed to be run manually by an admin on the server (not in CI — it requires Docker, systemd, and cgroup access).

Structure the test with the existing testing patterns (see testing/ directory):

1. **test_config_valid** — Validate resource-limits.yaml has aggregate sections for all groups
2. **test_generator_dry_run** — Run generate-user-slice-limits.py --dry-run and verify output contains CPUQuota, MemoryMax, MemoryHigh, TasksMax for each user
3. **test_cgroup_driver** — Verify Docker uses systemd cgroup driver
4. **test_slice_exists** — For each user with containers, verify their slice has a drop-in with resource limits
5. **test_memory_enforcement** — Create a test container with `--memory=1g`, verify it lands in correct cgroup and cgroup memory limit is set (read from /sys/fs/cgroup)
6. **test_aggregate_gpu_limit** — Verify get_resource_limits.py --aggregate includes gpu_limit
7. **test_wrapper_aggregate_check** — Verify docker-wrapper.sh contains aggregate quota check function
8. **test_psi_files_readable** — For user slices that exist, verify PSI files are readable
9. **test_login_greeting_syntax** — Validate ds01-quota-greeting.sh syntax

Output format:
```
[PASS] test_config_valid - aggregate sections present
[PASS] test_generator_dry_run - drop-in content generated
[FAIL] test_memory_enforcement - container not in expected cgroup
...
Results: 8/9 passed, 1 failed
```

Use simple test harness (functions returning 0/1, counter for pass/fail). No external test framework needed.

Mark tests that require root with `[ROOT]` prefix. Mark tests that require running containers with `[DOCKER]` prefix.

Make the script executable and place in testing/integration/.
  </action>
  <verify>
    - `bash -n testing/integration/test_resource_enforcement.sh` (syntax check)
    - `grep -c "^test_" testing/integration/test_resource_enforcement.sh` returns >= 7 (at least 7 test functions)
    - Script is executable pattern (has `#!/bin/bash` and `main()`)
  </verify>
  <done>Integration test validates config, generator, cgroup driver, slice limits, PSI availability, and wrapper changes</done>
</task>

</tasks>

<verification>
- Monitoring script syntax: `bash -n scripts/monitoring/collect-resource-stats.sh`
- Integration test syntax: `bash -n testing/integration/test_resource_enforcement.sh`
- Cron file exists: `test -f config/deploy/cron.d/ds01-resource-monitor`
- OOM tracking in monitoring: `grep -q "oom" scripts/monitoring/collect-resource-stats.sh`
- PSI reading in monitoring: `grep -q "pressure" scripts/monitoring/collect-resource-stats.sh`
</verification>

<success_criteria>
1. PSI metrics (cpu.pressure, memory.pressure) collected per user slice every minute
2. OOM kill events detected and logged to ds01 event system
3. Resource stats written as JSONL to /var/log/ds01/resource-stats.log
4. Integration test covers config, generator, cgroup driver, enforcement chain
5. Cron job deployed for continuous monitoring
</success_criteria>

<output>
After completion, create `.planning/phases/04-comprehensive-resource-enforcement/04-05-SUMMARY.md`
</output>
