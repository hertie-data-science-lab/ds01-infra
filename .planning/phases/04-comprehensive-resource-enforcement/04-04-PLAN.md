---
phase: 04-comprehensive-resource-enforcement
plan: 04
type: execute
wave: 3
depends_on: ["04-01", "04-02", "04-03"]
files_modified:
  - config/deploy/profile.d/ds01-quota-greeting.sh
  - scripts/user/helpers/check-limits
  - scripts/system/deploy.sh
autonomous: true

must_haves:
  truths:
    - "Users see a quota summary at SSH login showing CPU, memory, GPU usage vs limits"
    - "check-limits command shows aggregate CPU and memory usage alongside existing GPU/container display"
    - "Login greeting is concise and non-intrusive (fits in ~10 lines)"
    - "Admin users see 'unlimited' for aggregate limits"
  artifacts:
    - path: "config/deploy/profile.d/ds01-quota-greeting.sh"
      provides: "Login greeting showing quota summary"
      min_lines: 30
    - path: "scripts/user/helpers/check-limits"
      provides: "Extended check-limits with aggregate CPU/memory usage"
      contains: "memory.current"
  key_links:
    - from: "config/deploy/profile.d/ds01-quota-greeting.sh"
      to: "/sys/fs/cgroup/ds01.slice/"
      via: "reads cgroup stats for usage"
      pattern: "memory.current"
    - from: "config/deploy/profile.d/ds01-quota-greeting.sh"
      to: "scripts/docker/get_resource_limits.py"
      via: "calls --aggregate for limits"
      pattern: "--aggregate"
    - from: "scripts/user/helpers/check-limits"
      to: "/sys/fs/cgroup/ds01.slice/"
      via: "reads cgroup memory and CPU stats"
      pattern: "memory.current\\|cpu.stat"
---

<objective>
Create login greeting showing quota summary and extend check-limits to display aggregate CPU/memory usage.

Purpose: Per CONTEXT.md decision, users should see quota summary at SSH login. This is the primary way users discover their resource limits and current usage. The check-limits extension provides deeper detail on demand.

Output: New profile.d greeting script, extended check-limits with aggregate resource display.
</objective>

<execution_context>
@/home/datasciencelab/.claude/get-shit-done/workflows/execute-plan.md
@/home/datasciencelab/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/04-comprehensive-resource-enforcement/04-CONTEXT.md
@.planning/phases/04-comprehensive-resource-enforcement/04-01-SUMMARY.md
@.planning/phases/04-comprehensive-resource-enforcement/04-02-SUMMARY.md
@.planning/phases/04-comprehensive-resource-enforcement/04-03-SUMMARY.md
@scripts/user/helpers/check-limits
@config/deploy/profile.d/ds01-gpu-awareness.sh
@scripts/docker/get_resource_limits.py
@scripts/lib/init.sh
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create login quota greeting via profile.d</name>
  <files>
    config/deploy/profile.d/ds01-quota-greeting.sh
    scripts/system/deploy.sh
  </files>
  <action>
1. **Create config/deploy/profile.d/ds01-quota-greeting.sh** — A profile.d script that displays a concise quota summary at SSH login. Follow the pattern of existing profile.d scripts (ds01-gpu-awareness.sh):

   - Skip non-interactive shells: `[[ $- == *i* ]] || return 0`
   - Keep it FAST (< 200ms) — read cgroup files directly, avoid subprocess calls where possible
   - Use a Python one-liner or small inline script for parsing aggregate limits (calling get_resource_limits.py --aggregate is acceptable since it's only at login)
   - Format:

   ```
   DS01 Resource Quota — {username} ({group})
   ────────────────────────────────────────
   CPU:    ████████░░░░░░░░  52%  (50/96 cores)
   Memory: ██████░░░░░░░░░░  38%  (36G/96G)
   GPUs:   ████░░░░░░░░░░░░  33%  (1/3 slots)
   Tasks:  ██░░░░░░░░░░░░░░  12%  (1500/12288)
   ────────────────────────────────────────
   Run 'check-limits' for full details.
   ```

   - Progress bars: 16 chars wide, use simple block chars (█ and ░)
   - Colour coding: green (<70%), yellow (70-85%), red (>85%)
   - For admin users with no aggregate: show "unlimited" without bars
   - For CPU: read `/sys/fs/cgroup/ds01.slice/ds01-{group}-{user}.slice/cpu.stat` and parse `usage_usec`. CPU usage as percentage of quota is harder to show instantaneously — instead show the number of active tasks as a proxy, OR skip CPU bar and just show tasks + memory + GPU
   - Actually, CPU quota is enforced by kernel, not pre-checkable. Show: Memory, GPUs, Tasks (skip CPU bar — it's misleading without sustained measurement)
   - For memory: read `memory.current` from cgroup, divide by `memory_max` from aggregate
   - For GPUs: count from gpu-state.json (use the same approach as check-limits: `gpu-state-reader.py user-gpu-count`)
   - For tasks: read `pids.current` from cgroup
   - Handle missing cgroup files gracefully (user may not have a slice yet if no containers created)
   - Must be sourced (use `return` not `exit`)
   - Keep total output to ~8 lines (concise, not overwhelming)

2. **Update deploy.sh** — The deploy.sh already deploys profile.d scripts. Verify the new script will be picked up by the existing profile.d deployment loop. If not, add it. Ensure the permissions manifest sets 644 for this file.
  </action>
  <verify>
    - `bash -n config/deploy/profile.d/ds01-quota-greeting.sh` (syntax check)
    - `grep -q "memory.current\|pids.current" config/deploy/profile.d/ds01-quota-greeting.sh` (reads cgroup stats)
    - `grep -q "non-interactive\|\\$-" config/deploy/profile.d/ds01-quota-greeting.sh` (skips non-interactive)
    - The file uses `return` not `exit`
  </verify>
  <done>Login greeting shows concise quota usage bars for memory, GPUs, and tasks at SSH login</done>
</task>

<task type="auto">
  <name>Task 2: Extend check-limits with aggregate CPU/memory/tasks display</name>
  <files>
    scripts/user/helpers/check-limits
  </files>
  <action>
Extend the existing `check-limits` script to show aggregate resource usage alongside the existing GPU and container sections. Add a new "Aggregate Resource Usage" section.

1. **Add aggregate section** — After the existing GPU section and before the Container section, add:

```
Aggregate Resource Limits (per-user total):
  Memory:  ████████████░░░░░░░░ (38G / 96G, 40%)
  Tasks:   ██░░░░░░░░░░░░░░░░░░ (1500 / 12288, 12%)
```

2. **Read cgroup stats** — Add functions to read from the user's cgroup:
   - `get_memory_usage()`: reads `/sys/fs/cgroup/ds01.slice/ds01-{group}-{sanitized_user}.slice/memory.current` and converts to human-readable (GB)
   - `get_tasks_usage()`: reads `pids.current` from same cgroup path
   - Handle missing cgroup files gracefully (show "N/A" if slice doesn't exist)

3. **Get aggregate limits** — Call `python3 $SCRIPT_DIR/docker/get_resource_limits.py "$USERNAME" --aggregate` and parse the JSON output. Extract memory_max and tasks_max.

4. **Admin handling** — If aggregate limits are null (admin), show "unlimited" without bars (same pattern as existing GPU unlimited handling).

5. **Warning thresholds** — Add warnings for aggregate limits similar to existing GPU/container warnings:
   - Memory > 80%: yellow notice "MEMORY USAGE HIGH"
   - Memory > 95%: red warning "MEMORY LIMIT APPROACHING — containers may be OOM killed"
   - Tasks > 80%: yellow notice

6. **Reuse existing `usage_bar()` function** — The script already has a `usage_bar` function with colour thresholds. Reuse it for aggregate displays.

7. **Build the cgroup path** — Get the user's group from get_resource_limits.py --group, sanitize the username (source username-utils.sh which is already available via init.sh), and construct the cgroup path.

IMPORTANT: Do NOT remove or modify existing sections. The aggregate display is ADDITIVE.
  </action>
  <verify>
    - `bash -n scripts/user/helpers/check-limits` (syntax check)
    - `grep -q "memory.current" scripts/user/helpers/check-limits` (reads cgroup memory)
    - `grep -q "Aggregate\|aggregate" scripts/user/helpers/check-limits` (aggregate section present)
    - `grep -q "pids.current" scripts/user/helpers/check-limits` (reads task count)
  </verify>
  <done>check-limits displays aggregate memory and tasks usage alongside existing GPU/container display with colour-coded warnings</done>
</task>

</tasks>

<verification>
- Login greeting syntax: `bash -n config/deploy/profile.d/ds01-quota-greeting.sh`
- check-limits syntax: `bash -n scripts/user/helpers/check-limits`
- Login greeting is fast: measure with `time bash -c 'source config/deploy/profile.d/ds01-quota-greeting.sh'` (should be < 500ms)
- Both scripts handle missing cgroup files without error
</verification>

<success_criteria>
1. SSH login shows quota summary with memory, GPU, and tasks usage bars
2. check-limits shows aggregate resource usage section with memory and tasks
3. Both handle admin users (show "unlimited")
4. Both handle missing cgroup files gracefully (no errors)
5. Warnings shown when approaching limits (80%+ yellow, 95%+ red)
</success_criteria>

<output>
After completion, create `.planning/phases/04-comprehensive-resource-enforcement/04-04-SUMMARY.md`
</output>
