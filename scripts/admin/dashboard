#!/bin/bash
# Dashboard - Modular DS01 system dashboard with subcommands
# Main command: dashboard (replaces ds01-dashboard)

set -e

# Colors
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
CYAN='\033[0;36m'
BLUE='\033[0;34m'
BOLD='\033[1m'
DIM='\033[2m'
NC='\033[0m'

# Paths
QUERY_TOOL="/opt/ds01-infra/scripts/docker/ds01-resource-query.py"
SCRIPT_DIR="/opt/ds01-infra/scripts"

# ============================================================================
# SECTION FUNCTIONS
# ============================================================================

show_gpu_status() {
    # Show which GPUs have MIG mode enabled vs full GPU
    echo -e "${BOLD}GPU STATUS${NC}"
    echo -e "${CYAN}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€${NC}"

    if command -v nvidia-smi &>/dev/null; then
        nvidia-smi --query-gpu=index,name,mig.mode.current,memory.total --format=csv,noheader | \
            awk -F', ' 'BEGIN {printf "  %-5s %-25s %-12s %-12s\n", "GPU", "Name", "MIG Mode", "Memory"}
                        BEGIN {printf "  %-5s %-25s %-12s %-12s\n", "---", "----", "--------", "------"}
                        {
                            mig_status = ($3 == "Enabled") ? "MIG âœ“" : "Full GPU"
                            printf "  %-5s %-25s %-12s %-12s\n", $1, $2, mig_status, $4
                        }'
    else
        echo -e "${YELLOW}  nvidia-smi not available${NC}"
    fi
    echo ""
}

show_gpu_utilization() {
    # GPU utilization, allocation status, and system resources
    echo -e "${BOLD}GPU & SYSTEM UTILIZATION${NC}"
    echo -e "${CYAN}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€${NC}"
    echo ""

    # i) GPU Utilization (for non-MIG GPUs)
    if command -v nvidia-smi &>/dev/null; then
        echo -e "${BOLD}Physical GPU Utilization:${NC}"
        nvidia-smi --query-gpu=index,utilization.gpu,memory.used,memory.total --format=csv,noheader | \
            awk -F', ' '{
                if ($2 != "[N/A]" && $2 != "N/A") {
                    printf "  GPU %s: %s (Memory: %s / %s)\n", $1, $2, $3, $4
                }
            }' | head -n 10

        if ! nvidia-smi --query-gpu=utilization.gpu --format=csv,noheader | grep -qv "\[N/A\]"; then
            echo "  (All GPUs have MIG enabled - see MIG allocation status below)"
        fi
        echo ""
    fi

    # ii) GPU Allocation Status (MIG-aware)
    if [ -f "$QUERY_TOOL" ]; then
        echo -e "${BOLD}GPU ALLOCATION STATUS${NC}"

        python3 << 'PYEOF'
import sys
import subprocess
import re
sys.path.insert(0, '/opt/ds01-infra/scripts/docker')

import importlib.util
from pathlib import Path

SCRIPT_DIR = Path('/opt/ds01-infra/scripts/docker')

# Dynamic imports for hyphenated filenames
spec = importlib.util.spec_from_file_location('gpu_state_reader', str(SCRIPT_DIR / 'gpu-state-reader.py'))
gpu_state_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(gpu_state_module)
GPUStateReader = gpu_state_module.GPUStateReader

spec = importlib.util.spec_from_file_location('gpu_availability_checker', str(SCRIPT_DIR / 'gpu-availability-checker.py'))
gpu_avail_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(gpu_avail_module)
GPUAvailabilityChecker = gpu_avail_module.GPUAvailabilityChecker

def get_mig_process_memory():
    """Get per-MIG GPU memory usage"""
    try:
        result = subprocess.run(
            ['nvidia-smi', '--query-compute-apps=pid,used_memory,gpu_uuid', '--format=csv,noheader'],
            capture_output=True, text=True, check=True
        )

        mig_memory = {}
        for line in result.stdout.strip().split('\n'):
            if not line.strip():
                continue
            parts = [p.strip() for p in line.split(',')]
            if len(parts) >= 3:
                pid, mem_str, uuid = parts[0], parts[1], parts[2]
                mem_mb = int(re.search(r'\d+', mem_str).group())
                if uuid.startswith('MIG-'):
                    mig_memory[uuid] = mig_memory.get(uuid, 0) + mem_mb
        return mig_memory
    except:
        return {}

state_reader = GPUStateReader()
availability_checker = GPUAvailabilityChecker()

allocations = state_reader.get_all_allocations()
summary = availability_checker.get_allocation_summary()
mig_memory = get_mig_process_memory()

print(f"\n  Total MIG Instances: {summary['total_gpus']}")
print(f"  Allocated: {summary['allocated']} ({summary['utilization_percent']:.0f}%)")
print(f"  Available: {summary['available']}\n")

# Show each GPU/MIG allocation
for gpu_slot in sorted(allocations.keys()):
    info = allocations[gpu_slot]
    containers = info['containers']
    uuid = info['uuid']

    # Get memory usage for this MIG
    mem_used = mig_memory.get(uuid, 0)
    mem_str = f"{mem_used} MB" if mem_used > 0 else "idle"

    status_icon = "ðŸŸ¢" if len(containers) > 0 else "â—‹"
    print(f"  {status_icon} MIG {gpu_slot}: {len(containers)} container(s) | Mem: {mem_str}")

    for container in containers:
        print(f"     â””â”€ {container}")

PYEOF
        echo ""
    fi

    # iii) System Resources
    echo -e "${BOLD}SYSTEM RESOURCES${NC}"

    # CPU usage
    CPU_USAGE=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1)
    echo -e "  CPU Usage: ${CPU_USAGE}%"

    # Memory usage
    FREE_OUTPUT=$(free -h | grep Mem)
    MEM_TOTAL=$(echo $FREE_OUTPUT | awk '{print $2}')
    MEM_USED=$(echo $FREE_OUTPUT | awk '{print $3}')
    MEM_PERCENT=$(free | grep Mem | awk '{printf "%.0f", ($3/$2) * 100}')
    echo -e "  Memory: ${MEM_USED} / ${MEM_TOTAL} (${MEM_PERCENT}%)"

    # Disk usage
    DISK_USAGE=$(df -h / | tail -1 | awk '{print $5}')
    DISK_USED=$(df -h / | tail -1 | awk '{print $3}')
    DISK_TOTAL=$(df -h / | tail -1 | awk '{print $2}')
    echo -e "  Disk: ${DISK_USED} / ${DISK_TOTAL} (${DISK_USAGE})"

    echo ""
}

show_containers() {
    # Container overview (system-wide)
    echo -e "${BOLD}CONTAINER OVERVIEW (System-Wide)${NC}"
    echo -e "${CYAN}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€${NC}"

    if [ -f "$QUERY_TOOL" ]; then
        # Get all containers
        CONTAINERS_JSON=$(python3 "$QUERY_TOOL" containers --json 2>/dev/null)

        if [ -n "$CONTAINERS_JSON" ]; then
            python3 << PYEOF
import json
containers = json.loads('''$CONTAINERS_JSON''')

running = [c for c in containers if c['running']]
stopped = [c for c in containers if not c['running']]
with_gpu = [c for c in containers if c.get('gpu_allocated')]

print(f"  Total: {len(containers)} containers")
print(f"  Running: {len(running)} | Stopped: {len(stopped)}")
print(f"  With GPU: {len(with_gpu)}")
print()

# Show running containers
if running:
    print("  Running containers:")
    for c in running[:10]:  # Show max 10
        gpu_info = f" | GPU {c['gpu_allocated']}" if c.get('gpu_allocated') else ""
        print(f"    ðŸŸ¢ {c['name']} ({c['user']}){gpu_info}")

    if len(running) > 10:
        print(f"    ... and {len(running) - 10} more")
else:
    print("  No running containers")

PYEOF
        else
            echo -e "${YELLOW}  No containers found${NC}"
        fi
    else
        echo -e "${YELLOW}  Query tool not available${NC}"
    fi
    echo ""
}

show_users() {
    # System users and active sessions
    echo -e "${BOLD}SYSTEM USERS${NC}"
    echo -e "${CYAN}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€${NC}"

    # Logged in users
    LOGGED_IN=$(who | wc -l)
    echo -e "  Currently logged in: ${LOGGED_IN} user(s)"

    if [ $LOGGED_IN -gt 0 ]; then
        echo ""
        who | awk '{printf "  %s (from %s at %s %s)\n", $1, $5, $3, $4}' | sort -u
    fi

    echo ""

    # Users with running containers
    if [ -f "$QUERY_TOOL" ]; then
        echo -e "  Users with running containers:"
        python3 << 'PYEOF'
import json
import subprocess

result = subprocess.run(
    ['python3', '/opt/ds01-infra/scripts/docker/ds01-resource-query.py', 'containers', '--status', 'running', '--json'],
    capture_output=True, text=True
)

if result.returncode == 0 and result.stdout.strip():
    containers = json.loads(result.stdout)
    users = {}

    for c in containers:
        user = c['user']
        if user not in users:
            users[user] = {'containers': 0, 'gpus': 0}
        users[user]['containers'] += 1
        if c.get('gpu_allocated'):
            users[user]['gpus'] += 1

    for user in sorted(users.keys()):
        info = users[user]
        print(f"    â€¢ {user}: {info['containers']} container(s), {info['gpus']} GPU(s)")
else:
    print("    (none)")

PYEOF
    fi
    echo ""
}

show_allocations() {
    # Recent GPU allocations (last N)
    LIMIT=${1:-20}

    echo -e "${BOLD}RECENT GPU ALLOCATIONS (Last ${LIMIT})${NC}"
    echo -e "${CYAN}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€${NC}"

    LOG_FILE="/var/log/ds01/gpu-allocations.log"

    if [ -f "$LOG_FILE" ]; then
        tail -n "$LIMIT" "$LOG_FILE" | while IFS='|' read -r timestamp event user container gpu_id extra reason; do
            case "$event" in
                ALLOCATED)
                    icon="âœ“"
                    color="${GREEN}"
                    ;;
                RELEASED)
                    icon="â†“"
                    color="${BLUE}"
                    ;;
                REJECTED)
                    icon="âœ—"
                    color="${RED}"
                    ;;
                *)
                    icon="â€¢"
                    color="${NC}"
                    ;;
            esac

            short_time=$(date -d "$timestamp" '+%H:%M:%S' 2>/dev/null || echo "$timestamp")
            printf "  ${color}%-8s${NC} ${BOLD}%-10s${NC} %-15s %-25s %-8s %s\n" \
                "$short_time" "$event" "$user" "$container" "$gpu_id" "$reason"
        done
    else
        echo -e "${YELLOW}  No allocation log found${NC}"
    fi
    echo ""
}

show_system_info() {
    # System information section
    echo -e "${BOLD}SYSTEM INFORMATION${NC}"
    echo -e "${CYAN}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€${NC}"
    echo -e "  Hostname:     $(hostname)"
    echo -e "  Uptime:       $(uptime -p)"
    echo -e "  Kernel:       $(uname -r)"
    echo -e "  Date:         $(date)"
    echo ""
}

show_system_health() {
    # System health checks
    echo -e "${BOLD}SYSTEM HEALTH${NC}"
    echo -e "${CYAN}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€${NC}"

    # Docker status
    if systemctl is-active --quiet docker; then
        echo -e "  Docker:       ${GREEN}âœ“ Running${NC}"
    else
        echo -e "  Docker:       ${RED}âœ— Not running${NC}"
    fi

    # NVIDIA driver
    if command -v nvidia-smi &>/dev/null; then
        echo -e "  NVIDIA:       ${GREEN}âœ“ Available${NC}"
    else
        echo -e "  NVIDIA:       ${RED}âœ— Not available${NC}"
    fi

    # Disk space
    DISK_FREE=$(df -BG / | tail -1 | awk '{print $4}' | sed 's/G//')
    if [ "$DISK_FREE" -lt 10 ]; then
        echo -e "  Disk Space:   ${RED}âš  Low (${DISK_FREE}GB free)${NC}"
    else
        echo -e "  Disk Space:   ${GREEN}âœ“ OK (${DISK_FREE}GB free)${NC}"
    fi

    echo ""
}

show_quick_actions() {
    # Quick action shortcuts
    echo -e "${BOLD}Quick Actions:${NC}"
    echo -e "  ${CYAN}dashboard util${NC}          Show GPU utilization and allocation details"
    echo -e "  ${CYAN}dashboard container${NC}     Show all running containers"
    echo -e "  ${CYAN}dashboard users${NC}         Show active users and their containers"
    echo -e "  ${CYAN}dashboard allocations${NC}   Show recent GPU allocation history"
    echo -e "  ${CYAN}dashboard --full${NC}        Show complete dashboard"
    echo ""
}

# ============================================================================
# HELP & USAGE
# ============================================================================

show_help() {
    cat << EOF

${BOLD}${CYAN}Dashboard - DS01 System Dashboard${NC}

${BOLD}Usage:${NC}
  dashboard [subcommand] [options]

${BOLD}Subcommands:${NC}

  (default)                 Quick summary: GPU status, allocations, quick actions
  ${GREEN}--full${NC}                   Complete dashboard (all sections)

  ${GREEN}mig-status${NC}               Show which GPUs have MIG mode vs full GPU
  ${GREEN}util${NC}                     GPU utilization, allocation status, system resources
  ${GREEN}container${NC}                Running containers and resource usage
  ${GREEN}users${NC}                    Active users and their container/GPU usage
  ${GREEN}allocations [N]${NC}          Recent GPU allocations (default: last 20)

${BOLD}Options:${NC}

  -h, --help, --info       Show this help message

${BOLD}Examples:${NC}

  dashboard                 # Quick summary
  dashboard --full          # Complete view
  dashboard util            # GPU utilization details
  dashboard allocations 50  # Show last 50 allocations

${BOLD}Related Commands:${NC}

  gpu-dashboard             Detailed GPU allocation status
  container-dashboard       Container-specific resource dashboard
  ds01-status              User-facing status

${BOLD}Aliases:${NC}

  ds01-dashboard           â†’ dashboard (legacy compatibility)

EOF
    exit 0
}

# ============================================================================
# MAIN LOGIC
# ============================================================================

# Check for help flags
if [[ "$1" == "-h" ]] || [[ "$1" == "--help" ]] || [[ "$1" == "--info" ]]; then
    show_help
fi

# Print header
print_header() {
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo -e "${BOLD}              DS01 GPU SERVER DASHBOARD${NC}"
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo ""
}

# Handle subcommands
SUBCOMMAND="${1:-summary}"

case "$SUBCOMMAND" in
    --full)
        # Full dashboard (everything)
        print_header
        show_system_info
        show_gpu_status
        show_gpu_utilization
        show_containers
        show_users
        show_system_health
        show_allocations 5
        ;;

    mig-status)
        # Just MIG status
        print_header
        show_gpu_status
        ;;

    util|utilization)
        # GPU utilization and resources
        print_header
        show_gpu_utilization
        ;;

    container|containers)
        # Container overview
        print_header
        show_containers
        ;;

    users|user)
        # User overview
        print_header
        show_users
        ;;

    allocations|allocs)
        # Recent allocations
        print_header
        LIMIT="${2:-20}"
        show_allocations "$LIMIT"
        ;;

    summary|*)
        # Default summary view
        print_header
        show_gpu_status
        show_allocations 5
        show_quick_actions
        ;;
esac
