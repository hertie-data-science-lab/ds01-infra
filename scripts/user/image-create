#!/bin/bash
# Create custom Docker image for DS01
# Interactive wizard for building personalized ML/DL images

BLUE='\033[94m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
CYAN='\033[0;36m'
BOLD='\033[1m'
DIM='\033[2m'
NC='\033[0m'

USERNAME=$(whoami)
USER_ID=$(id -u)
GROUP_ID=$(id -g)
DOCKERFILES_DIR="$HOME/dockerfiles"
PROJECT_DOCKERFILE=false

# Source username utilities for sanitization
source "/opt/ds01-infra/scripts/lib/username-utils.sh"
SANITIZED_USERNAME=$(sanitize_username_for_slice "$USERNAME")

usage() {
    echo ""
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo -e "${BOLD}Docker Image Creator${NC}"
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo ""
    echo -e "${CYAN}Usage:${NC}"
    echo "  image-create [image-name] [options]"
    echo ""
    echo -e "${CYAN}Options:${NC}"
    echo "  -f, --framework FRAMEWORK   Base framework (pytorch, tensorflow, jax)"
    echo "  -t, --type TYPE            Use case type (cv, nlp, rl, ml, custom)"
    echo "  -p, --packages PACKAGES    Additional Python packages (space-separated)"
    echo "  -s, --system PACKAGES      System packages via apt (space-separated)"
    echo "  --project-dockerfile       Store Dockerfile in project dir (~/workspace/<project>/)"
    echo "  --no-build                 Create Dockerfile only, don't build image"
    echo "  --guided                   Show detailed explanations for beginners"
    echo "  -h, --help                 Show this help message"
    echo ""
    echo -e "${CYAN}Frameworks:${NC}"
    echo "  pytorch      PyTorch 2.5.1 + CUDA 11.8 (default)"
    echo "  tensorflow   TensorFlow 2.14.0 + CUDA 11.8"
    echo "  jax          JAX + CUDA"
    echo ""
    echo -e "${CYAN}Use Case Types:${NC}"
    echo -e "  cv       Computer Vision ${DIM}(incl: timm, albumentations, opencv)${NC}"
    echo -e "  nlp      Natural Language Processing ${DIM}(incl: transformers, datasets)${NC}"
    echo -e "  rl       Reinforcement Learning ${DIM}(incl: gymnasium, stable-baselines3)${NC}"
    echo -e "  ml       General ML ${DIM}(incl scikit-learn, xgboost, lightgbm)${NC}"
    echo -e "  custom   Specify all packages manually"
    echo ""
    echo -e "${CYAN}Examples:${NC}"
    echo "  image-create my-cv-project                    # Interactive mode"
    echo "  image-create thesis-model -f pytorch -t cv    # CV project with PyTorch"
    echo "  image-create nlp-exp -f pytorch -t nlp -p \"wandb optuna\"  # With extra packages"
    echo "  image-create custom-setup -t custom --no-build  # Just create Dockerfile"
    echo ""
    echo -e "${CYAN}Quick Start:${NC}"
    echo -e "  1. Run: ${GREEN}image-create my-project${NC}"
    echo "  2. Answer prompts to customise"
    echo "  3. Wait a few minutes for build"
    echo -e "  4. Then run: ${GREEN}container-deploy my-project${NC}"
    echo ""
    echo -e "${DIM}Run 'help' or 'commands' anytime to see available commands.${NC}"
    echo ""
}

show_base_image_packages() {
    # Display key packages from AIME base image
    local base_image="$1"

    echo -e "${CYAN}â”â”â” AIME Base Image Packages â”â”â”${NC}"
    echo ""
    echo -e "${BOLD}Pre-installed in ${CYAN}$base_image:${NC}:"
    # Key packages that are consistent across AIME images
    echo -e "  ${BOLD}Nvidia GPU libs:${NC} CUDA 12.6.3, cuDNN, NCCL, nvidia-* packages (10+ CUDA dependencies)"
    echo -e "  ${BOLD}DL Frameworks:${NC} torch, torchvision, torchaudio (PyTorch ecosystem)"
    echo -e "  ${BOLD}Core Scientific Computing:${NC} numpy & pillow"
    echo -e "  ${BOLD}Utilities:${NC}: conda, ipython, psutil, tqdm"
    echo ""
    if [ "$GUIDED" = true ]; then
        echo -e "${YELLOW}ğŸ’¡ Note:${NC} AIME base images are optimized for ML/DL workloads."
        echo "    They include essential DL frameworks and GPU libraries (133 packages total),"
        echo "    but omit heavier data science packages to keep image size manageable." 
        echo "    You can add additional packages as needed in the next steps."
        echo ""
        echo -e "${CYAN}Currently missing:${NC}"
        echo "    â€¢ Jupyter Lab (for notebooks)"
        echo "    â€¢ pandas, scipy, scikit-learn (data science)"
        echo "    â€¢ matplotlib, seaborn (visualisation)"
        echo "    â€¢ Domain-specific: opencv, transformers, etc."
        echo ""
    fi

    if [ "$GUIDED" = true ]; then
        echo -e "${DIM}To see full package list: docker run --rm $base_image pip list${NC}"
        echo ""
    fi

    read -p "Press Enter to continue..." </dev/tty
    echo ""
}

detect_cuda_arch() {
    # Auto-detect appropriate CUDA architecture based on host driver
    # Driver 535+ supports CUDA 12.x, older drivers use CUDA 11.8
    local driver_major
    driver_major=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader 2>/dev/null | head -1 | cut -d. -f1)

    if [ -n "$driver_major" ] && [ "$driver_major" -ge 535 ] 2>/dev/null; then
        echo "CUDA_ADA"
    else
        echo "CUDA_AMPERE"
    fi
}

get_base_image() {
    local framework="$1"
    local custom_image="$2"
    local version="$3"  # Optional version parameter

    # Handle custom base image (bypass catalog)
    if [ "$framework" = "custom" ]; then
        echo "$custom_image"
        return 0
    fi

    # Look up in AIME v2 catalog (150+ pre-built framework images)
    local AIME_REPO="/opt/ds01-infra/aime-ml-containers/ml_images.repo"

    if [ -f "$AIME_REPO" ]; then
        # Capitalize framework name (AIME uses Pytorch, Tensorflow)
        local framework_capital=$(echo "$framework" | sed 's/tf/tensorflow/; s/\b\(.\)/\u\1/g')

        # Determine GPU architecture based on host driver (auto-detect if not specified)
        # Driver 535+ supports CUDA 12.x (CUDA_ADA), older drivers use CUDA 11.8 (CUDA_AMPERE)
        local arch="${MLC_ARCH:-$(detect_cuda_arch)}"

        # Look up specific version or latest
        local image=""
        if [ -n "$version" ]; then
            # Find exact version match (architecture in brackets: [CUDA_ADA])
            image=$(awk -F', ' -v fw="$framework_capital" -v ver="$version" -v arch="[$arch]" \
                '$1 == fw && $2 == ver && $3 == arch {print $4; exit}' "$AIME_REPO")
        fi

        # If no version specified or not found, get latest for this architecture
        if [ -z "$image" ]; then
            image=$(awk -F', ' -v fw="$framework_capital" -v arch="[$arch]" \
                '$1 == fw && $3 == arch {print $4; exit}' "$AIME_REPO")
        fi

        if [ -n "$image" ]; then
            echo "$image"
            [ -n "$VERBOSE" ] && echo -e "${GREEN}âœ“${NC} Using AIME v2 catalog image: ${YELLOW}$image${NC}" >&2
            return 0
        fi
    fi

    # Fallback: AIME catalog not found or framework not in catalog
    [ -n "$VERBOSE" ] && echo -e "${YELLOW}âš ${NC} AIME catalog not available, using Docker Hub fallback" >&2

    case $framework in
        tensorflow|tf)
            echo "tensorflow/tensorflow:2.14.0-gpu"
            ;;
        jax)
            echo "nvcr.io/nvidia/jax:23.10-py3"
            ;;
        pytorch-cpu)
            echo "pytorch/pytorch:2.5.1-cpu"
            ;;
        *)
            # Match fallback to auto-detected architecture
            if [ "$(detect_cuda_arch)" = "CUDA_ADA" ]; then
                echo "pytorch/pytorch:2.5.1-cuda12.1-cudnn9-runtime"
            else
                echo "pytorch/pytorch:2.5.1-cuda11.8-cudnn9-runtime"
            fi
            ;;
    esac
}

get_jupyter_packages() {
    # Jupyter and interactive tools
    echo "jupyter jupyterlab ipykernel ipywidgets notebook"
}

get_data_science_packages() {
    # Core data science packages (NOT in AIME base)
    echo "pandas scipy scikit-learn matplotlib seaborn"
}

normalize_package_name() {
    # Normalize package name: lowercase, strip version specifiers
    local pkg="$1"
    # Remove version specifiers (==, >=, <=, ~=, etc.)
    pkg=$(echo "$pkg" | sed 's/[=<>~!].*//')
    # Convert to lowercase
    echo "$pkg" | tr '[:upper:]' '[:lower:]'
}

check_duplicate_packages() {
    # Check if any input packages are already in existing packages
    # Args: $1 = new packages (space-separated), $2... = existing package lists
    local new_packages="$1"
    shift
    local existing_packages="$*"

    # Build array of existing packages (normalized)
    local existing_array=()
    for pkg in $existing_packages; do
        local normalized=$(normalize_package_name "$pkg")
        existing_array+=("$normalized")
    done

    # Check each new package
    local duplicates=()
    for new_pkg in $new_packages; do
        local new_normalized=$(normalize_package_name "$new_pkg")
        for existing in "${existing_array[@]}"; do
            if [ "$new_normalized" = "$existing" ]; then
                duplicates+=("$new_pkg")
                break
            fi
        done
    done

    # Return duplicates (space-separated)
    if [ ${#duplicates[@]} -gt 0 ]; then
        echo "${duplicates[@]}"
        return 1
    fi
    return 0
}

check_user_limits() {
    # Check user's resource limits and provide helpful information
    local limits_script="/opt/ds01-infra/scripts/docker/get_resource_limits.py"

    if [ ! -f "$limits_script" ]; then
        # Silently skip if script not available
        return 0
    fi

    # Get user's limits
    local limit_info=$(python3 "$limits_script" "$USERNAME" 2>/dev/null)

    if [ $? -eq 0 ] && [ -n "$limit_info" ]; then
        # Parse limits from the formatted output
        local group=$(echo "$limit_info" | head -1 | sed -n 's/.*group: \([^)]*\).*/\1/p')
        local max_containers=$(echo "$limit_info" | grep "Max containers:" | awk '{print $NF}')
        local max_gpus=$(echo "$limit_info" | grep "Max GPUs (simultaneous):" | awk '{print $NF}')

        # Count current containers
        local current_containers=$(docker ps -a --filter "label=maintainer=$USERNAME" --format "{{.ID}}" 2>/dev/null | wc -l)

        # Only show if we got valid data
        if [ -n "$group" ] && [ -n "$max_containers" ]; then
            echo ""
            echo -e "${CYAN}â”â”â” Your Resource Limits â”â”â”${NC}"
            echo ""
            echo -e "${BOLD}Group:${NC} $group"
            echo -e "${BOLD}Max Containers:${NC} $max_containers (currently have: $current_containers)"
            echo -e "${BOLD}Max GPUs/MIGs:${NC} $max_gpus"
            echo ""

            # Warning if approaching limits
            if [ "$max_containers" != "unlimited" ] && [ "$current_containers" -ge "$max_containers" ] 2>/dev/null; then
                echo -e "${RED}âš  WARNING: Container Limit Reached${NC}"
                echo ""
                echo "You already have $current_containers containers (limit: $max_containers)."
                echo "You won't be able to create a new container from this image"
                echo "until you stop/remove an existing container."
                echo ""
                echo -e "View containers: ${GREEN}container-list${NC}"
                echo -e "Retire container:  ${GREEN}container-retire <name>${NC}"
                echo ""
                read -p "Continue creating image anyway? [y/N]: " CONTINUE </dev/tty
                if [[ ! "$CONTINUE" =~ ^[Yy]$ ]]; then
                    echo "Cancelled."
                    exit 0
                fi
            elif [ "$max_containers" != "unlimited" ] && [ "$current_containers" -ge $((max_containers - 1)) ] 2>/dev/null; then
                echo -e "${YELLOW}âš  Note: You're at $current_containers/$max_containers containers.${NC}"
                echo "  You can create this image, but may need to stop a container"
                echo "  before creating a new one from it."
                echo ""
            fi

            # Info about GPU-based images
            if [ "$FRAMEWORK" != "pytorch-cpu" ] && [ "$FRAMEWORK" != "custom" ]; then
                echo -e "${BOLD}GPU Access:${NC}"
                echo "  This image includes CUDA/GPU support."
                if [ "$max_gpus" = "unlimited" ]; then
                    echo "  You have unlimited GPU access."
                else
                    echo "  You can allocate up to $max_gpus GPU(s) across all containers."
                fi
                echo ""
            fi
        fi
    fi
}

get_usecase_packages() {
    local usecase="$1"
    case $usecase in
        cv)
            echo "timm albumentations opencv-python-headless torchvision"
            ;;
        nlp)
            echo "transformers datasets tokenizers accelerate sentencepiece"
            ;;
        rl)
            echo "gymnasium stable-baselines3 tensorboard"
            ;;
        ml)
            echo "xgboost lightgbm catboost optuna"
            ;;
        *)
            echo ""
            ;;
    esac
}

interactive_mode() {
    if [ "$GUIDED" = false ]; then
        echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
        echo -e "${BOLD}Create a Custom Docker Image${NC}"
        echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
        echo ""
    fi

    # Image name
    if [ -z "$IMAGE_NAME" ]; then
        read -p "Image name (e.g., my-project, thesis-cv): " IMAGE_NAME </dev/tty
        IMAGE_NAME=$(echo "$IMAGE_NAME" | tr ' ' '-' | tr '[:upper:]' '[:lower:]')
    fi
    echo ""
    # New naming convention: ds01-{user-id}/{project-name}:latest
    FULL_IMAGE_NAME="ds01-${USER_ID}/${IMAGE_NAME}"

    # Check if exists
    if docker images --format "{{.Repository}}:{{.Tag}}" | grep -q "^${FULL_IMAGE_NAME}:latest$"; then
        echo -e "${YELLOW}âš  Image '$FULL_IMAGE_NAME:latest' already exists${NC}"
        echo ""
        read -p "Overwrite? [y/N]: " OVERWRITE </dev/tty
        echo ""
        if [[ ! "$OVERWRITE" =~ ^[Yy]$ ]]; then
            echo "Cancelled."
            exit 0
        fi
    fi

    echo -e "${BOLD}Image repo will be named: ${CYAN}${IMAGE_NAME}${NC}"
    echo -e "${BOLD}Image namespace will be: ${CYAN}ds01-${USER_ID}${NC}\n"
    if [ "$GUIDED" = true ]; then
        echo -e "${DIM}Full image reference will be "{namespace}/{repo_name}:{tag}": ${CYAN}${FULL_IMAGE_NAME}:latest${NC}"
        echo -e "${DIM}Here, the {namespace} is given by 'ds01-{user-id}', and we apply a default tag 'latest'.${NC}\n"
    fi

    # Framework
    if [ -z "$FRAMEWORK" ]; then
        if [ "$GUIDED" = true ]; then
            echo -e "${BOLD}Choosing a Framework${NC}"
            echo ""
            echo "A framework is the foundation for your ML/DL work:"
            echo ""
            echo -e "â€¢ ${CYAN}PyTorch${NC} - Most popular, great community, PyTorch + torchvision"
            echo "  Used by: Most research, computer vision, NLP"
            echo ""
            echo -e "â€¢ ${CYAN}TensorFlow${NC} - Google's framework, production-ready"
            echo "  Used by: Industry applications, deployment"
            echo ""
            echo -e "â€¢ ${CYAN}JAX${NC} - High-performance, functional approach"
            echo "  Used by: Research, custom algorithms"
            echo ""
            echo -e "â€¢ ${CYAN}PyTorch CPU${NC} - No GPU, for testing or CPU-only work"
            echo ""
            echo -e "â€¢ ${CYAN}Custom${NC} - Specify your own base image (advanced)"
            echo "  Use any Docker image as base (e.g., ubuntu:22.04, python:3.11)"
            echo ""
            echo -e "${YELLOW}ğŸ’¡ Recommendation:${NC} Choose PyTorch unless you have specific needs"
            echo ""
        fi

        echo -e "${BOLD}Select base framework:${NC}"
        echo -e "  ${BOLD}1)${NC} PyTorch (latest from AIME catalog) ${GREEN}(recommended)${NC}"
        echo -e "  ${BOLD}2)${NC} TensorFlow (latest from AIME catalog)"
        echo -e "  ${BOLD}3)${NC} JAX + CUDA (if available)"
        echo -e "  ${BOLD}4)${NC} PyTorch CPU-only"
        echo -e "  ${BOLD}5)${NC} Custom (specify base image)"
        echo -e ""
        read -p "Choice [1-5, default: 1]: " FW_CHOICE </dev/tty

        case $FW_CHOICE in
            2) FRAMEWORK="tensorflow" ;;
            3) FRAMEWORK="jax" ;;
            4) FRAMEWORK="pytorch-cpu" ;;
            5)
                FRAMEWORK="custom"
                echo ""
                echo -e "${BOLD}Custom Base Image${NC}"
                echo "Enter Docker image (e.g., ubuntu:22.04, python:3.11-slim, nvidia/cuda:12.0-runtime)"
                read -p "> " CUSTOM_BASE_IMAGE </dev/tty
                if [ -z "$CUSTOM_BASE_IMAGE" ]; then
                    echo -e "${RED}Error: Base image cannot be empty${NC}"
                    exit 1
                fi
                echo -e "${YELLOW}âš  Custom base: No default packages will be installed${NC}"
                SKIP_BASE_PACKAGES=true
                ;;
            *) FRAMEWORK="pytorch" ;;
        esac

        # Get actual base image from AIME catalog
        if [ "$FRAMEWORK" != "custom" ]; then
            SELECTED_BASE_IMAGE=$(get_base_image "$FRAMEWORK" "$CUSTOM_BASE_IMAGE")
            echo ""
            echo -e "${GREEN}âœ“${NC} Selected base image: ${CYAN}$SELECTED_BASE_IMAGE${NC}"
            echo ""

            # Show what's already in the AIME base image
            if [ "$GUIDED" = true ] || [ "$SKIP_BASE_PACKAGES" != true ]; then
                show_base_image_packages "$SELECTED_BASE_IMAGE"
            fi
        fi
    fi

    # Phase 2: Core Python & Jupyter
    if [ -z "$JUPYTER_CHOICE" ] && [ "$SKIP_BASE_PACKAGES" != true ]; then
        if [ "$GUIDED" = true ]; then
            echo ""
            echo -e "${BOLD}Phase 2: Core Python & Interactive (Jupyter)${NC}"
            echo ""
            echo "These enable notebook-based development:"
            echo ""
            echo -e "  ${CYAN}Default packages:${NC}"
            echo "  â€¢ jupyter - Jupyter ecosystem"
            echo "  â€¢ jupyterlab - Web-based IDE"
            echo "  â€¢ ipykernel - Python kernel for notebooks"
            echo "  â€¢ ipywidgets - Interactive widgets"
            echo ""
            echo -e "${YELLOW}ğŸ’¡ Package Versions:${NC}"
            echo "  â€¢ Without version: installs latest (e.g., 'pandas')"
            echo "  â€¢ With version: installs specific (e.g., 'pandas==1.5.3', 'transformers>=4.30.0')"
            echo ""
            echo -e "${YELLOW}ğŸ’¡ Recommendation:${NC} Install if you use notebooks"
            echo ""
        fi

        if [ "$GUIDED" = false ]; then
            echo -e "${CYAN}â”â”â”â” Choose Defaults â”â”â”â”${NC}"
            echo ""
        fi

        echo -e "${BOLD}Install Jupyter Lab & interactive tools?${NC}"
        echo -e "  ${BOLD}1)${NC} Yes - Install defaults (${GREEN}recommended${NC})"
        echo -e "  ${BOLD}2)${NC} No - Skip (use terminal/IDE only)"
        echo -e "  ${BOLD}3)${NC} Custom - Specify packages manually"
        echo ""
        read -p "Choice [1-3, default: 1]: " JUPYTER_PKG_CHOICE </dev/tty

        case $JUPYTER_PKG_CHOICE in
            2)
                JUPYTER_CHOICE="skip"
                echo -e "${YELLOW}Skipped Jupyter packages${NC}"
                ;;
            3)
                JUPYTER_CHOICE="custom"
                # Loop until no duplicates
                while true; do
                    echo ""
                    echo -e "${BOLD}Specify Jupyter packages:${NC} (space-separated)"
                    echo -e "${DIM}Examples: jupyterlab ipywidgets ipykernel==6.25.0${NC}"
                    read -p "> " CUSTOM_JUPYTER_PACKAGES </dev/tty

                    if [ -z "$CUSTOM_JUPYTER_PACKAGES" ]; then
                        echo -e "${YELLOW}No packages entered${NC}"
                        break
                    fi

                    # Check for duplicates (against AIME base packages)
                    local aime_base="numpy pillow tqdm conda ipython psutil torch torchvision torchaudio"
                    local duplicates=$(check_duplicate_packages "$CUSTOM_JUPYTER_PACKAGES" "$aime_base")

                    if [ $? -eq 1 ]; then
                        echo ""
                        echo -e "${YELLOW}âš   Warning: These packages are already in AIME base:${NC}"
                        echo -e "   ${YELLOW}$duplicates${NC}"
                        echo ""
                        echo "Please enter different packages (or press Enter to go back):"
                    else
                        break
                    fi
                done
                ;;
            *)
                JUPYTER_CHOICE="default"
                ;;
        esac
        echo ""
    fi

    # Phase 3: Core Data Science
    if [ -z "$DATA_SCIENCE_CHOICE" ] && [ "$SKIP_BASE_PACKAGES" != true ]; then
        if [ "$GUIDED" = true ]; then
            echo ""
            echo -e "${BOLD}Phase 3: Core Data Science${NC}"
            echo ""
            echo "Essential libraries for data analysis:"
            echo ""
            echo -e "  ${CYAN}Default packages:${NC}"
            echo "  â€¢ pandas - DataFrames & data manipulation"
            echo "  â€¢ scipy - Scientific computing"
            echo "  â€¢ scikit-learn - Traditional ML algorithms"
            echo "  â€¢ matplotlib, seaborn - Visualisation"
            echo ""
            echo -e "${YELLOW}âš  Note:${NC} These are NOT in AIME base (only numpy included)\n"
            echo -e "${YELLOW}ğŸ’¡ Recommendation:${NC} Install defaults (needed for most DS work)"
            echo ""
        fi
        echo -e "${BOLD}Install core data science packages?${NC}"
        echo -e "  ${BOLD}1)${NC} Yes - Install defaults (${GREEN}recommended${NC})"
        echo -e "  ${BOLD}2)${NC} No - Skip (framework-only setup)"
        echo -e "  ${BOLD}3)${NC} Custom - Specify packages manually"
        echo ""
        read -p "Choice [1-3, default: 1]: " DS_PKG_CHOICE </dev/tty

        case $DS_PKG_CHOICE in
            2)
                DATA_SCIENCE_CHOICE="skip"
                echo -e "${YELLOW}Skipped data science packages${NC}"
                ;;
            3)
                DATA_SCIENCE_CHOICE="custom"
                # Loop until no duplicates
                while true; do
                    echo ""
                    echo -e "${BOLD}Specify data science packages:${NC} (space-separated)"
                    read -p "> " CUSTOM_DS_PACKAGES </dev/tty

                    if [ -z "$CUSTOM_DS_PACKAGES" ]; then
                        echo -e "${YELLOW}No packages entered${NC}"
                        break
                    fi

                    # Check for duplicates (against AIME base + Jupyter packages)
                    local aime_base="numpy pillow tqdm conda ipython psutil torch torchvision torchaudio"
                    local jupyter_pkgs=""
                    if [ "$JUPYTER_CHOICE" = "default" ]; then
                        jupyter_pkgs=$(get_jupyter_packages)
                    elif [ "$JUPYTER_CHOICE" = "custom" ]; then
                        jupyter_pkgs="$CUSTOM_JUPYTER_PACKAGES"
                    fi

                    local duplicates=$(check_duplicate_packages "$CUSTOM_DS_PACKAGES" "$aime_base" "$jupyter_pkgs")

                    if [ $? -eq 1 ]; then
                        echo ""
                        echo -e "${YELLOW}âš   Warning: These packages are already included:${NC}"
                        echo -e "   ${YELLOW}$duplicates${NC}"
                        echo ""
                        echo "Please enter different packages (or press Enter to go back):"
                    else
                        break
                    fi
                done
                ;;
            *)
                DATA_SCIENCE_CHOICE="default"
                ;;
        esac
        echo ""
    fi

    # Phase 4: Use-Case Specific
    if [ -z "$USECASE" ] && [ "$SKIP_BASE_PACKAGES" != true ]; then
        if [ "$GUIDED" = true ]; then
            echo ""
            echo -e "${BOLD}Phase 4: Use-Case Specific Packages${NC}"
            echo ""
            echo "This determines which specialised packages get installed:"
            echo ""
            echo -e "â€¢ ${CYAN}General ML${NC} - Advanced ML with boosting algorithms"
            echo "  Packages: xgboost, lightgbm, catboost, optuna"
            echo "  Example: Classification, regression, hyperparameter tuning"
            echo ""
            echo -e "â€¢ ${CYAN}Computer Vision (CV)${NC} - Images, videos, object detection"
            echo "  Packages: timm, albumentations, opencv, torchvision"
            echo "  Example: Image classification, object detection, segmentation"
            echo ""
            echo -e "â€¢ ${CYAN}NLP${NC} - Text, language models, transformers"
            echo "  Packages: transformers, datasets, tokenizers, accelerate"
            echo "  Example: Text classification, translation, chatbots"
            echo ""
            echo -e "â€¢ ${CYAN}Reinforcement Learning${NC} - Agents, environments, decision making"
            echo "  Packages: gymnasium, stable-baselines3"
            echo "  Example: Game AI, robotics, optimization"
            echo ""
            echo -e "â€¢ ${CYAN}Custom${NC} - Skip use case packages or specify manually"
            echo ""
        fi

        echo -e "${BOLD}Select use case (additional domain-specific packages):${NC}"
        echo -e "  ${BOLD}1)${NC} General ML ${DIM}(xgboost, lightgbm, catboost, optuna)${NC} (${GREEN}default${NC})"
        echo -e "  ${BOLD}2)${NC} Computer Vision ${DIM}(timm, albumentations, opencv)${NC}"
        echo -e "  ${BOLD}3)${NC} NLP ${DIM}(transformers, datasets, tokenizers)${NC}"
        echo -e "  ${BOLD}4)${NC} Reinforcement Learning ${DIM}(gymnasium, stable-baselines3)${NC}"
        echo -e "  ${BOLD}5)${NC} Custom (${DIM}specify packages manually${NC}"
        echo ""
        read -p "Choice [1-5, default: 1]: " UC_CHOICE </dev/tty

        case $UC_CHOICE in
            2) USECASE="cv" ;;
            3) USECASE="nlp" ;;
            4) USECASE="rl" ;;
            5)
                USECASE="custom"
                echo ""
                echo -e "${BOLD}Custom Use Case Packages${NC}"
                echo "Specify packages (space-separated), or press Enter to skip:"
                read -p "> " CUSTOM_USECASE_PACKAGES </dev/tty
                ;;
            1|"") USECASE="ml" ;;
            *)
                echo "Invalid choice. Setting to default: General ML."
                USECASE="ml"
                ;;
        esac
    fi

    # Display included packages before asking for additional
    if [ -z "$USECASE" ] && [ "$SKIP_BASE_PACKAGES" != "true" ]; then
        echo ""
        echo -e "${CYAN}â”â”â” Packages To Be Installed â”â”â”${NC}"
        echo ""

        # Jupyter packages
        if [ "$JUPYTER_CHOICE" = "default" ]; then
            echo -e "${BOLD}Jupyter & Interactive:${NC}"
            echo "  jupyter, jupyterlab, ipykernel, ipywidgets, notebook"
            echo ""
        elif [ "$JUPYTER_CHOICE" = "custom" ]; then
            echo -e "${BOLD}Jupyter (custom):${NC}"
            echo "  $CUSTOM_JUPYTER_PACKAGES"
            echo ""
        elif [ "$JUPYTER_CHOICE" = "skip" ]; then
            echo -e "${BOLD}Jupyter:${NC} Skipped"
            echo ""
        fi

        # Data Science packages
        if [ "$DATA_SCIENCE_CHOICE" = "default" ]; then
            echo -e "${BOLD}Data Science:${NC}"
            echo "  pandas, scipy, scikit-learn, matplotlib, seaborn"
            echo ""
        elif [ "$DATA_SCIENCE_CHOICE" = "custom" ]; then
            echo -e "${BOLD}Data Science (custom):${NC}"
            echo "  $CUSTOM_DS_PACKAGES"
            echo ""
        elif [ "$DATA_SCIENCE_CHOICE" = "skip" ]; then
            echo -e "${BOLD}Data Science:${NC} Skipped"
            echo ""
        fi

        # Use case packages
        if [ "$USECASE" != "custom" ] && [ -n "$USECASE" ]; then
            local uc_pkgs=$(get_usecase_packages "$USECASE")
            if [ -n "$uc_pkgs" ]; then
                echo -e "${BOLD}Use Case Packages ($USECASE):${NC}"
                echo "  $uc_pkgs"
                echo ""
            fi
        elif [ "$USECASE" = "custom" ] && [ -n "$CUSTOM_USECASE_PACKAGES" ]; then
            echo -e "${BOLD}Use Case Packages (custom):${NC}"
            echo "  $CUSTOM_USECASE_PACKAGES"
            echo ""
        fi
    fi

    # Additional packages
    if [ -z "$ADDITIONAL_PACKAGES" ]; then
        while true; do
            echo ""
            echo -e "${CYAN}â”â”â” Add Custom-specified packages? â”â”â”${NC}"
            echo ""
            echo -e "${BOLD}Space-separated${NC} (or press Enter to skip)"
            echo -e "${DIM}Examples: wandb pytorch-lightning==1.5.3${NC}"
            read -p "> " ADDITIONAL_PACKAGES </dev/tty

            if [ -z "$ADDITIONAL_PACKAGES" ]; then
                break
            fi

            # Check for duplicates (against ALL previous selections)
            local aime_base="numpy pillow tqdm conda ipython psutil torch torchvision torchaudio"
            local jupyter_pkgs=""
            local ds_pkgs=""
            local usecase_pkgs=""

            if [ "$JUPYTER_CHOICE" = "default" ]; then
                jupyter_pkgs=$(get_jupyter_packages)
            elif [ "$JUPYTER_CHOICE" = "custom" ]; then
                jupyter_pkgs="$CUSTOM_JUPYTER_PACKAGES"
            fi

            if [ "$DATA_SCIENCE_CHOICE" = "default" ]; then
                ds_pkgs=$(get_data_science_packages)
            elif [ "$DATA_SCIENCE_CHOICE" = "custom" ]; then
                ds_pkgs="$CUSTOM_DS_PACKAGES"
            fi

            if [ -n "$USECASE" ] && [ "$USECASE" != "custom" ]; then
                usecase_pkgs=$(get_usecase_packages "$USECASE")
            elif [ "$USECASE" = "custom" ] && [ -n "$CUSTOM_USECASE_PACKAGES" ]; then
                usecase_pkgs="$CUSTOM_USECASE_PACKAGES"
            fi

            local duplicates=$(check_duplicate_packages "$ADDITIONAL_PACKAGES" "$aime_base" "$jupyter_pkgs" "$ds_pkgs" "$usecase_pkgs")

            if [ $? -eq 1 ]; then
                echo ""
                echo -e "${YELLOW}âš   Warning: These packages are already included:${NC}"
                echo -e "   ${YELLOW}$duplicates${NC}"
                echo ""
                echo "Please enter different packages (or press Enter to skip):"
            else
                break
            fi
        done
    fi

    # System packages
    if [ -z "$SYSTEM_PACKAGES" ]; then
        echo -e "\n${BOLD}System packages (apt)?${NC} (or press Enter to skip)"
        echo -e "${DIM}Examples: htop tmux vim git-lfs${NC}"
        read -p "> " SYSTEM_PACKAGES </dev/tty
        echo ""
    fi
}

create_dockerfile() {
    local image_name="$1"
    local framework="$2"
    local usecase="$3"
    local additional="$4"
    local system_pkgs="$5"
    local custom_base="$6"
    local jupyter_choice="$7"          # NEW: jupyter/interactive packages
    local custom_jupyter_pkgs="$8"     # NEW: custom jupyter packages
    local data_science_choice="$9"     # NEW: data science packages
    local custom_ds_pkgs="${10}"       # NEW: custom DS packages
    local custom_usecase_pkgs="${11}"
    local skip_base="${12}"

    local base_image=$(get_base_image "$framework" "$custom_base")
    local usecase_packages=$(get_usecase_packages "$usecase")

    # Handle custom use case packages
    if [ "$usecase" = "custom" ] && [ -n "$custom_usecase_pkgs" ]; then
        usecase_packages="$custom_usecase_pkgs"
    elif [ "$usecase" = "custom" ]; then
        usecase_packages=""
    fi

    # Determine Dockerfile location based on flag
    local dockerfile_dir="$DOCKERFILES_DIR"
    if [ "$PROJECT_DOCKERFILE" = true ] && [ -n "$PROJECT_DIR" ]; then
        dockerfile_dir="$PROJECT_DIR"
    fi

    mkdir -p "$dockerfile_dir"
    # Extract project name from full image name (ds01-1001/test-project -> test-project)
    local project_name="${image_name##*/}"  # Remove everything before the last /
    local dockerfile="$dockerfile_dir/${project_name}.Dockerfile"

    cat > "$dockerfile" << DOCKERFILEEOF
# DS01 Custom Image: $project_name
# Created: $(date)
# Framework: $framework
# Use case: $usecase
# Author: $USERNAME

FROM $base_image

LABEL maintainer="$USERNAME"
LABEL maintainer.id="$USER_ID"
LABEL aime.mlc.base_image="$base_image"
LABEL aime.mlc.project="$project_name"
LABEL aime.mlc.user_id="$USER_ID"
LABEL aime.mlc.username="$USERNAME"
LABEL aime.mlc.DS01_MANAGED="true"
LABEL aime.mlc.DS01_IMAGE="$project_name"
LABEL aime.mlc.DS01_FRAMEWORK="$framework"
LABEL aime.mlc.DS01_CREATED="$(date -Iseconds)"

WORKDIR /workspace

DOCKERFILEEOF

    # Only add system packages and Python packages if not using fully custom base
    if [ "$skip_base" != true ]; then
        cat >> "$dockerfile" << 'DOCKERFILEEOF'
# System packages
RUN apt-get update && apt-get install -y --no-install-recommends \
    git \
    curl \
    wget \
    vim \
    htop \
DOCKERFILEEOF

        # Add user's system packages if provided
        if [ -n "$system_pkgs" ]; then
            # Split packages and add each on its own line
            for pkg in $system_pkgs; do
                echo "    $pkg \\" >> "$dockerfile"
            done
        fi

        cat >> "$dockerfile" << 'DOCKERFILEEOF'
    && rm -rf /var/lib/apt/lists/*

DOCKERFILEEOF

        # Phase 2: Jupyter & Interactive packages
        if [ "$jupyter_choice" = "skip" ]; then
            echo "# Jupyter packages skipped by user" >> "$dockerfile"
            echo "" >> "$dockerfile"
        elif [ "$jupyter_choice" = "custom" ] && [ -n "$custom_jupyter_pkgs" ]; then
            echo "# Jupyter & Interactive (Custom)" >> "$dockerfile"
            echo "RUN pip install --no-cache-dir \\" >> "$dockerfile"
            local pkg_array=($custom_jupyter_pkgs)
            local pkg_count=${#pkg_array[@]}
            local i=0
            for pkg in "${pkg_array[@]}"; do
                ((i++))
                if [ $i -lt $pkg_count ]; then
                    echo "    $pkg \\" >> "$dockerfile"
                else
                    echo "    $pkg" >> "$dockerfile"
                fi
            done
            echo "" >> "$dockerfile"
        elif [ "$jupyter_choice" = "default" ]; then
            local jupyter_packages=$(get_jupyter_packages)
            echo "# Jupyter & Interactive" >> "$dockerfile"
            echo "RUN pip install --no-cache-dir \\" >> "$dockerfile"
            local pkg_array=($jupyter_packages)
            local pkg_count=${#pkg_array[@]}
            local i=0
            for pkg in "${pkg_array[@]}"; do
                ((i++))
                if [ $i -lt $pkg_count ]; then
                    echo "    $pkg \\" >> "$dockerfile"
                else
                    echo "    $pkg" >> "$dockerfile"
                fi
            done
            echo "" >> "$dockerfile"
        fi

        # Phase 3: Data Science packages
        if [ "$data_science_choice" = "skip" ]; then
            echo "# Data science packages skipped by user" >> "$dockerfile"
            echo "" >> "$dockerfile"
        elif [ "$data_science_choice" = "custom" ] && [ -n "$custom_ds_pkgs" ]; then
            echo "# Core Data Science (Custom)" >> "$dockerfile"
            echo "RUN pip install --no-cache-dir \\" >> "$dockerfile"
            local pkg_array=($custom_ds_pkgs)
            local pkg_count=${#pkg_array[@]}
            local i=0
            for pkg in "${pkg_array[@]}"; do
                ((i++))
                if [ $i -lt $pkg_count ]; then
                    echo "    $pkg \\" >> "$dockerfile"
                else
                    echo "    $pkg" >> "$dockerfile"
                fi
            done
            echo "" >> "$dockerfile"
        elif [ "$data_science_choice" = "default" ]; then
            local ds_packages=$(get_data_science_packages)
            echo "# Core Data Science" >> "$dockerfile"
            echo "RUN pip install --no-cache-dir \\" >> "$dockerfile"
            local pkg_array=($ds_packages)
            local pkg_count=${#pkg_array[@]}
            local i=0
            for pkg in "${pkg_array[@]}"; do
                ((i++))
                if [ $i -lt $pkg_count ]; then
                    echo "    $pkg \\" >> "$dockerfile"
                else
                    echo "    $pkg" >> "$dockerfile"
                fi
            done
            echo "" >> "$dockerfile"
        fi

        # Use case specific packages
        if [ -n "$usecase_packages" ]; then
            echo "# Use case specific packages" >> "$dockerfile"
            echo "RUN pip install --no-cache-dir \\" >> "$dockerfile"
            local pkg_array=($usecase_packages)
            local pkg_count=${#pkg_array[@]}
            local i=0
            for pkg in "${pkg_array[@]}"; do
                ((i++))
                if [ $i -lt $pkg_count ]; then
                    echo "    $pkg \\" >> "$dockerfile"
                else
                    echo "    $pkg" >> "$dockerfile"
                fi
            done
            echo "" >> "$dockerfile"
        fi

        # Additional user packages
        if [ -n "$additional" ]; then
            echo "# Additional user packages" >> "$dockerfile"
            echo "RUN pip install --no-cache-dir \\" >> "$dockerfile"
            local pkg_array=($additional)
            local pkg_count=${#pkg_array[@]}
            local i=0
            for pkg in "${pkg_array[@]}"; do
                ((i++))
                if [ $i -lt $pkg_count ]; then
                    echo "    $pkg \\" >> "$dockerfile"
                else
                    echo "    $pkg" >> "$dockerfile"
                fi
            done
            echo "" >> "$dockerfile"
        fi

        # Always add custom section for future additions
        cat >> "$dockerfile" << DOCKERFILEEOF
# Custom additional packages

DOCKERFILEEOF
    else
        echo "# Custom base image - no default packages installed" >> "$dockerfile"
        echo "" >> "$dockerfile"
    fi

    # Jupyter configuration (only if Jupyter was installed)
    if [ "$skip_base" != true ] && [ "$jupyter_choice" = "default" ] || [ "$jupyter_choice" = "custom" ]; then
        cat >> "$dockerfile" << DOCKERFILEEOF
# Configure Jupyter Lab
RUN jupyter lab --generate-config && \\
    echo "c.ServerApp.ip = '0.0.0.0'" >> /root/.jupyter/jupyter_lab_config.py && \\
    echo "c.ServerApp.allow_root = True" >> /root/.jupyter/jupyter_lab_config.py && \\
    echo "c.ServerApp.open_browser = False" >> /root/.jupyter/jupyter_lab_config.py && \\
    echo "c.ServerApp.token = ''" >> /root/.jupyter/jupyter_lab_config.py && \\
    echo "c.ServerApp.password = ''" >> /root/.jupyter/jupyter_lab_config.py

# IPython kernel
RUN python -m ipykernel install --user \\
    --name=$project_name \\
    --display-name="$project_name ($framework)"

DOCKERFILEEOF
    fi

    # User/Group Setup (DS01 optimization - avoids slow docker commit at container creation)
    # These ARGs are passed at build time via --build-arg
    cat >> "$dockerfile" << 'DOCKERFILEEOF'
# User/Group Setup (DS01 - baked into image to avoid docker commit at container creation)
ARG DS01_USER_ID
ARG DS01_GROUP_ID
ARG DS01_USERNAME

# Create user/group with specific UID:GID matching host user
RUN set -e && \
    if [ -n "$DS01_USER_ID" ] && [ -n "$DS01_GROUP_ID" ] && [ -n "$DS01_USERNAME" ]; then \
        echo "DS01: Setting up user $DS01_USERNAME (UID=$DS01_USER_ID, GID=$DS01_GROUP_ID)" && \
        # Step 1: Remove conflicting group if exists with different name
        EXISTING_GROUP=$(getent group $DS01_GROUP_ID 2>/dev/null | cut -d: -f1 || true) && \
        if [ -n "$EXISTING_GROUP" ] && [ "$EXISTING_GROUP" != "$DS01_USERNAME" ]; then \
            echo "DS01: Removing conflicting group $EXISTING_GROUP (has GID $DS01_GROUP_ID)" && \
            groupdel "$EXISTING_GROUP" 2>/dev/null || true; \
        fi && \
        # Step 2: Create group with specific GID
        if ! getent group $DS01_USERNAME >/dev/null 2>&1; then \
            addgroup --gid $DS01_GROUP_ID $DS01_USERNAME; \
        fi && \
        # Step 3: Remove conflicting user if exists with different name
        EXISTING_USER=$(getent passwd $DS01_USER_ID 2>/dev/null | cut -d: -f1 || true) && \
        if [ -n "$EXISTING_USER" ] && [ "$EXISTING_USER" != "$DS01_USERNAME" ]; then \
            echo "DS01: Removing conflicting user $EXISTING_USER (has UID $DS01_USER_ID)" && \
            userdel -r "$EXISTING_USER" 2>/dev/null || true; \
        fi && \
        # Step 4: Create user with specific UID and GID
        if ! getent passwd $DS01_USERNAME >/dev/null 2>&1; then \
            adduser --disabled-password --gecos "" --uid $DS01_USER_ID --gid $DS01_GROUP_ID $DS01_USERNAME; \
        fi && \
        # Step 4b: CRITICAL - Truncate lastlog/faillog to prevent huge sparse files
        # High UIDs (e.g., 1722830498) cause these files to grow to 300GB+
        # which breaks Docker overlay2 layer export
        : > /var/log/lastlog && \
        : > /var/log/faillog && \
        # Step 5: Configure sudo access (NOPASSWD)
        usermod -aG sudo $DS01_USERNAME && \
        echo "$DS01_USERNAME ALL=(ALL) NOPASSWD:ALL" >> /etc/sudoers && \
        # Step 6: Create .local/bin directory for pip --user installs
        mkdir -p /home/$DS01_USERNAME/.local/bin && \
        chown -R $DS01_USER_ID:$DS01_GROUP_ID /home/$DS01_USERNAME && \
        # Step 7: Configure PATH in bashrc (matches AIME docker run setup)
        # Add ~/.local/bin to PATH for pip install --user packages
        echo 'export PATH="$HOME/.local/bin:$PATH"' >> /home/$DS01_USERNAME/.bashrc && \
        # Step 8: Configure HOME export (fixes LDAP username issues)
        echo "export HOME=/home/$DS01_USERNAME" >> /home/$DS01_USERNAME/.bashrc && \
        # Step 9: Configure PS1 prompt (matches AIME docker run setup)
        # Uses container hostname which Docker sets from --name or container ID
        # Format: [container-name] user@host:path$
        echo 'export PS1='"'"'[\h] \u@ds01:\w\$ '"'"'' >> /home/$DS01_USERNAME/.bashrc && \
        chown $DS01_USER_ID:$DS01_GROUP_ID /home/$DS01_USERNAME/.bashrc && \
        echo "DS01: User setup complete"; \
    else \
        echo "DS01: Skipping user setup (build args not provided)"; \
    fi

DOCKERFILEEOF

    # Store user info in labels for mlc-patched.py to verify and skip commit
    cat >> "$dockerfile" << DOCKERFILEEOF
# DS01 Labels for container creation optimization
LABEL aime.mlc.DS01_HAS_USER_SETUP="true"
LABEL aime.mlc.DS01_USER_ID="$USER_ID"
LABEL aime.mlc.DS01_GROUP_ID="$GROUP_ID"
LABEL aime.mlc.DS01_USERNAME="$SANITIZED_USERNAME"

DOCKERFILEEOF

    # Final environment variables and CMD
    cat >> "$dockerfile" << DOCKERFILEEOF
# Environment variables
ENV PYTHONUNBUFFERED=1
ENV CUDA_DEVICE_ORDER=PCI_BUS_ID
ENV HF_HOME=/workspace/.cache/huggingface
ENV TORCH_HOME=/workspace/.cache/torch
ENV MPLCONFIGDIR=/workspace/.cache/matplotlib

CMD ["/bin/bash"]
DOCKERFILEEOF

    echo "$dockerfile"
}

# Parse arguments
IMAGE_NAME=""
FRAMEWORK=""
USECASE=""
ADDITIONAL_PACKAGES=""
SYSTEM_PACKAGES=""
CUSTOM_BASE_IMAGE=""
JUPYTER_CHOICE=""
CUSTOM_JUPYTER_PACKAGES=""
DATA_SCIENCE_CHOICE=""
CUSTOM_DS_PACKAGES=""
CUSTOM_USECASE_PACKAGES=""
SKIP_BASE_PACKAGES=false
NO_BUILD=false
GUIDED=false

while [[ $# -gt 0 ]]; do
    case $1 in
        -f|--framework)
            FRAMEWORK="$2"
            shift 2
            ;;
        -t|--type|--type=*)
            if [[ "$1" == --type=* ]]; then
                USECASE="${1#*=}"
                shift
            else
                USECASE="$2"
                shift 2
            fi
            ;;
        -p|--packages)
            ADDITIONAL_PACKAGES="$2"
            shift 2
            ;;
        -s|--system)
            SYSTEM_PACKAGES="$2"
            shift 2
            ;;
        --project-dockerfile)
            PROJECT_DOCKERFILE=true
            shift
            ;;
        --no-build)
            NO_BUILD=true
            shift
            ;;
        --guided)
            GUIDED=true
            shift
            ;;
        -h|--help|--info)
            usage
            exit 0
            ;;
        -*)
            echo -e "${RED}Unknown option: $1${NC}\n"
            usage
            exit 1
            ;;
        *)
            if [ -z "$IMAGE_NAME" ]; then
                IMAGE_NAME="$1"
            else
                echo -e "${RED}Multiple image names specified${NC}\n"
                usage
                exit 1
            fi
            shift
            ;;
    esac
done

# Handle --project-dockerfile flag
if [ "$PROJECT_DOCKERFILE" = true ]; then
    # Try to determine project name from image name
    if [ -n "$IMAGE_NAME" ]; then
        # Remove -image suffix if present
        PROJECT_NAME="${IMAGE_NAME%-image}"
        PROJECT_DIR="$HOME/workspace/$PROJECT_NAME"

        # Create project directory if it doesn't exist
        if [ ! -d "$PROJECT_DIR" ]; then
            echo -e "${YELLOW}âš  Project directory does not exist: $PROJECT_DIR${NC}"
            read -p "Create it now? [Y/n]: " CREATE_DIR </dev/tty
            CREATE_DIR=${CREATE_DIR:-Y}
            if [[ "$CREATE_DIR" =~ ^[Yy]$ ]]; then
                mkdir -p "$PROJECT_DIR"
                echo -e "${GREEN}âœ“ Created $PROJECT_DIR${NC}"
            else
                echo -e "${RED}Cannot use --project-dockerfile without project directory${NC}"
                echo "Falling back to centralized location: ~/dockerfiles/"
                PROJECT_DOCKERFILE=false
                PROJECT_DIR=""
            fi
        fi
    else
        echo -e "${YELLOW}âš  --project-dockerfile requires an image name${NC}"
        PROJECT_DOCKERFILE=false
    fi
fi

# Show guided introduction
if [ "$GUIDED" = true ]; then
    echo ""
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo -e "${BOLD}Docker Image Creation - Guided Mode${NC}"
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo ""
    echo -e "${BOLD}What is a Docker Image?${NC}"
    echo ""
    echo "  A Docker image is a blueprint for your computing environment:"
    echo "  â€¢ Contains operating system (Ubuntu Linux)"
    echo "  â€¢ Pre-installed software (Python, PyTorch, TensorFlow, etc.)"
    echo "  â€¢ All libraries and dependencies"
    echo "  â€¢ Configuration and settings"
    echo ""
    echo -e "${BOLD}Why Create a Custom Image?${NC}"
    echo ""
    echo "  You create an image to:"
    echo "  â€¢ Install specific Python packages you need"
    echo "  â€¢ Set up your preferred ML/DL framework version"
    echo "  â€¢ Include domain-specific libraries (CV, NLP, RL)"
    echo "  â€¢ Save time - install once, use many times"
    echo ""
    echo -e "${YELLOW}ğŸ’¡ Pro Tip: ${BOLD}Image vs Container:${NC}"
    echo ""
    echo -e "  â€¢ ${CYAN}Image${NC} = Blueprint (like a recipe)"
    echo -e "  â€¢ ${CYAN}Container${NC} = Running instance (like the cooked dish)"
    echo "  â€¢ One image can create many containers"
    echo "  â€¢ Containers inherit everything from the image"
    echo ""
    echo -e "${BOLD}The Process:${NC}"
    echo ""
    echo "  1. Choose base framework (PyTorch, TensorFlow, JAX)"
    echo "  2. Select use case (CV, NLP, RL, or general ML)"
    echo "  3. Add extra packages if needed"
    echo "  4. Build image (takes 3-5 minutes, depending on existing cache)"
    echo "  5. Create containers from this image"
    echo ""
    read -p "Press Enter to start creating your image..." </dev/tty
    echo ""
fi

# Interactive mode if missing info
if [ -z "$IMAGE_NAME" ] || [ -z "$FRAMEWORK" ] || [ -z "$USECASE" ]; then
    interactive_mode
else
    # Non-interactive: sanitize image name and use USER_ID (not USERNAME which may contain @)
    IMAGE_NAME=$(echo "$IMAGE_NAME" | tr ' ' '-' | tr '[:upper:]' '[:lower:]')
    # Use same naming convention as interactive mode: ds01-{user-id}/{project-name}
    FULL_IMAGE_NAME="ds01-${USER_ID}/${IMAGE_NAME}"
fi

# Check user's resource limits and provide helpful info
check_user_limits

# Create Dockerfile
echo -e "${CYAN}Creating Dockerfile...${NC}\n"

echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${GREEN}${BOLD}âœ“ Phase 1/2: Complete${NC}"
echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo ""

DOCKERFILE=$(create_dockerfile "$FULL_IMAGE_NAME" "$FRAMEWORK" "$USECASE" "$ADDITIONAL_PACKAGES" "$SYSTEM_PACKAGES" "$CUSTOM_BASE_IMAGE" "$JUPYTER_CHOICE" "$CUSTOM_JUPYTER_PACKAGES" "$DATA_SCIENCE_CHOICE" "$CUSTOM_DS_PACKAGES" "$CUSTOM_USECASE_PACKAGES" "$SKIP_BASE_PACKAGES")
echo -e "${GREEN}âœ“${NC} Dockerfile created: ${BLUE}$DOCKERFILE${NC}\n"


# Guided explanation of Dockerfile
if [ "$GUIDED" = true ]; then
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo -e "${BOLD}What is a Dockerfile?${NC}"
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo ""
    echo "A Dockerfile is a recipe for building your image:"
    echo ""
    echo -e "  â€¢ ${CYAN}FROM${NC} - Start with a base image (PyTorch, TensorFlow, etc.)"
    echo -e "  â€¢ ${CYAN}RUN${NC} - Execute commands (install packages, configure)"
    echo -e "  â€¢ ${CYAN}ENV${NC} - Set environment variables"
    echo -e "  â€¢ ${CYAN}WORKDIR${NC} - Set working directory"
    echo ""
    echo "Your Dockerfile is saved at:"
    echo -e "  ${BLUE}$DOCKERFILE${NC}"
    echo ""
    echo "You can edit it later to:"
    echo "  â€¢ Add more packages"
    echo "  â€¢ Change configurations"
    echo "  â€¢ Install system tools"
    echo ""
    echo -e "Then rebuild with: ${GREEN}image-update $FULL_IMAGE_NAME${NC}"
    echo ""
fi

# Phase 2: Build Image?
BUILD_IMAGE=true
if [ "$NO_BUILD" = true ]; then
    BUILD_IMAGE=false
    echo -e "${YELLOW}Build skipped (--no-build flag)${NC}"
    echo ""
    build_context=$(dirname "$DOCKERFILE")
    echo "Build later with:"
    echo -e "  ${GREEN}docker build --build-arg DS01_USER_ID=$USER_ID --build-arg DS01_GROUP_ID=$GROUP_ID --build-arg DS01_USERNAME=$SANITIZED_USERNAME -t $FULL_IMAGE_NAME:latest -f $DOCKERFILE $build_context/${NC}"
    echo ""
else
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo -e "${BOLD}Phase 2/2: Build Docker Image${NC}"
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    if [ "$GUIDED" = true ]; then
        echo ""
        echo "This will:"
        echo "  â€¢ Download base image"
        echo "  â€¢ Install all packages"
        echo "  â€¢ Configure Jupyter and Python"
        echo "  â€¢ Save final image (~18 GB)"
        echo ""
    fi
    echo -e "${DIM}This can take a few minutes${NC}"
    echo ""
    read -p "Build image now? [Y/n]: " BUILD_CONFIRM </dev/tty
    BUILD_CONFIRM=${BUILD_CONFIRM:-Y}
    echo ""

    if [[ ! "$BUILD_CONFIRM" =~ ^[Yy]$ ]]; then
        BUILD_IMAGE=false
        echo "Build skipped."
        echo ""
        build_context=$(dirname "$DOCKERFILE")
        echo "Build later with:"
        echo -e "  ${GREEN}docker build --build-arg DS01_USER_ID=$USER_ID --build-arg DS01_GROUP_ID=$GROUP_ID --build-arg DS01_USERNAME=$SANITIZED_USERNAME -t $FULL_IMAGE_NAME:latest -f $DOCKERFILE $build_context/${NC}"
        echo ""
    fi
fi

# Build image if confirmed
IMAGE_BUILT=false
if [ "$BUILD_IMAGE" = true ]; then
    echo -e "${CYAN}Building image... (this takes 3-5 minutes, depending on existing cache)${NC}\n"

    # Use the directory containing the Dockerfile as build context
    build_context=$(dirname "$DOCKERFILE")
    # Pass user info as build args for user/group setup inside image
    if docker build \
        --build-arg DS01_USER_ID="$USER_ID" \
        --build-arg DS01_GROUP_ID="$GROUP_ID" \
        --build-arg DS01_USERNAME="$SANITIZED_USERNAME" \
        -t "$FULL_IMAGE_NAME:latest" \
        -f "$DOCKERFILE" \
        "$build_context/"; then
        IMAGE_BUILT=true

        # Save metadata (sanitize filename - replace / with _)
        mkdir -p "$HOME/ds01-config/images"
        METADATA_FILE=$(echo "$FULL_IMAGE_NAME" | tr '/' '_')
        cat > "$HOME/ds01-config/images/${METADATA_FILE}.info" << INFOEOF
Image: $FULL_IMAGE_NAME
Framework: $FRAMEWORK
Use Case: $USECASE
Created: $(date)
Dockerfile: $DOCKERFILE

Packages:
$([ -n "$(get_usecase_packages $USECASE)" ] && echo "- Use case: $(get_usecase_packages $USECASE)")
$([ -n "$ADDITIONAL_PACKAGES" ] && echo "- Additional: $ADDITIONAL_PACKAGES")
$([ -n "$SYSTEM_PACKAGES" ] && echo "- System: $SYSTEM_PACKAGES")
INFOEOF

        echo ""
        echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
        echo -e "${GREEN}${BOLD}âœ“ Phase 2/2: Image Built Successfully${NC}"
        echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
        echo ""
        echo -e "${BOLD}Image reference:${NC} ${CYAN}$FULL_IMAGE_NAME:latest${NC}\n"
        echo -e "${DIM}Metadata saved to:${NC} ${DIM}$HOME/ds01-config/images/${METADATA_FILE}.info${NC}"
        echo -e "${DIM}Dockerfile location:${NC} ${DIM}$DOCKERFILE${NC}"

        if [ "$GUIDED" = true ]; then
            echo ""
            echo -e "${BOLD}What Just Happened?${NC}"
            echo ""
            echo "  âœ“ Downloaded base image with $FRAMEWORK"
            echo "  âœ“ Installed all requested packages"
            echo "  âœ“ Configured Jupyter Lab"
            echo "  âœ“ Set up Python environment"
            echo ""
            echo " Next steps: create & deploy a container based on your image:"
            echo -e "  ${GREEN}container-deploy $IMAGE_NAME${NC}"
        fi
    else
        echo ""
        echo -e "${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
        echo -e "${RED}${BOLD}âœ— Phase 2/2: Build Failed${NC}"
        echo -e "${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
        echo ""
        echo "Check Dockerfile: $DOCKERFILE"
        echo ""
        exit 1
    fi
fi

# Image creation complete - suggest next steps
if [ "$IMAGE_BUILT" = true ]; then
    echo ""
    echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo -e "${GREEN}${BOLD}âœ“ Image Built Successfully${NC}"
    echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo ""

    if [ "$GUIDED" = true ]; then
        echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
        echo -e "${BOLD}What Just Happened?${NC}"
        echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
        echo ""
        echo "You've created a Docker image - a blueprint for containers."
        echo ""
        echo -e "  â€¢ ${CYAN}Dockerfile${NC} = Recipe (text file with build instructions)"
        echo -e "  â€¢ ${CYAN}Image${NC} = Blueprint (built from Dockerfile, stored by Docker)"
        echo -e "  â€¢ ${CYAN}Container${NC} = Running instance (where you actually work)"
        echo ""
        echo "Think of it like: Recipe â†’ Executable Program â†’ Running Process"
        echo ""
        echo -e "${BOLD}Next Step: Create a Container${NC}"
        echo ""
        echo "An image is just a blueprint. To actually use it, you need to"
        echo "create & deploy a container - a running instance where you'll do your work."
        echo ""
        echo "Deploy container:"
        echo -e "  ${GREEN}container-deploy $IMAGE_NAME${NC}"
        echo ""
        echo "This will:"
        echo "  â€¢ Create a container from your image"
        echo "  â€¢ Allocate GPU resources"
        echo "  â€¢ Mount your workspace directory"
        echo "  â€¢ Apply resource limits"
        echo ""
        echo -e "${BOLD}Other Useful Commands:${NC}"
        echo -e "  ${GREEN}image-list${NC}          List all your images"
        echo -e "  ${GREEN}image-update${NC}        Update Dockerfile & rebuild this image"
        echo -e "  ${GREEN}container-list${NC}      List all containers"
        echo -e "  ${GREEN}container-deploy${NC}       Deploy a container"
        echo ""
    else
        echo -e "${BOLD}Next Step:${NC}"
        echo -e "  ${GREEN}container-deploy $IMAGE_NAME${NC}"
    fi
fi
